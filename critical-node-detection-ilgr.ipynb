{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f38a6d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:01.425094Z",
     "iopub.status.busy": "2025-03-20T09:59:01.424790Z",
     "iopub.status.idle": "2025-03-20T09:59:07.708068Z",
     "shell.execute_reply": "2025-03-20T09:59:07.707008Z"
    },
    "papermill": {
     "duration": 6.292613,
     "end_time": "2025-03-20T09:59:07.709673",
     "exception": false,
     "start_time": "2025-03-20T09:59:01.417060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3cf23",
   "metadata": {
    "papermill": {
     "duration": 0.006173,
     "end_time": "2025-03-20T09:59:07.722748",
     "exception": false,
     "start_time": "2025-03-20T09:59:07.716575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577a2e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:07.736066Z",
     "iopub.status.busy": "2025-03-20T09:59:07.735783Z",
     "iopub.status.idle": "2025-03-20T09:59:19.326140Z",
     "shell.execute_reply": "2025-03-20T09:59:19.325231Z"
    },
    "papermill": {
     "duration": 11.598883,
     "end_time": "2025-03-20T09:59:19.327840",
     "exception": false,
     "start_time": "2025-03-20T09:59:07.728957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61559591",
   "metadata": {
    "papermill": {
     "duration": 0.005944,
     "end_time": "2025-03-20T09:59:19.340422",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.334478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Graph Robustness Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216af4e",
   "metadata": {
    "papermill": {
     "duration": 0.00586,
     "end_time": "2025-03-20T09:59:19.352310",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.346450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. Effective Graph Resistance (EGR)**  \n",
    "   $$\n",
    "   R_g = \\frac{2}{N-1} \\sum_{i=1}^{N-c} \\frac{1}{\\lambda_i}\n",
    "   $$\n",
    "   where $ \\lambda_i $ are the eigenvalues of the Laplacian matrix of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188073b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.365441Z",
     "iopub.status.busy": "2025-03-20T09:59:19.364980Z",
     "iopub.status.idle": "2025-03-20T09:59:19.369097Z",
     "shell.execute_reply": "2025-03-20T09:59:19.368474Z"
    },
    "papermill": {
     "duration": 0.011939,
     "end_time": "2025-03-20T09:59:19.370220",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.358281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_effective_resistance(graph):\n",
    "    laplacian = nx.laplacian_matrix(graph).toarray()\n",
    "    eigenvalues = np.linalg.eigvalsh(laplacian)\n",
    "    eigenvalues = eigenvalues[eigenvalues > 1e-8]  # Avoid zero eigenvalues\n",
    "    N = graph.number_of_nodes()\n",
    "    return (2 / (N - 1)) * np.sum(1 / eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e407c40",
   "metadata": {
    "papermill": {
     "duration": 0.005985,
     "end_time": "2025-03-20T09:59:19.382302",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.376317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2. Weighted Spectrum (WS)**  \n",
    "   $$\n",
    "   W_s = \\sum_i (1 - \\lambda_i)^n\n",
    "   $$\n",
    "   where $ n $ controls the depth of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b868d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.395464Z",
     "iopub.status.busy": "2025-03-20T09:59:19.395188Z",
     "iopub.status.idle": "2025-03-20T09:59:19.398901Z",
     "shell.execute_reply": "2025-03-20T09:59:19.398090Z"
    },
    "papermill": {
     "duration": 0.011716,
     "end_time": "2025-03-20T09:59:19.400051",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.388335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weighted_spectrum(graph, n=3):\n",
    "    laplacian = nx.normalized_laplacian_matrix(graph).toarray()\n",
    "    eigenvalues = np.linalg.eigvalsh(laplacian)\n",
    "    return np.sum((1 - eigenvalues) ** n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc8d83",
   "metadata": {
    "papermill": {
     "duration": 0.007256,
     "end_time": "2025-03-20T09:59:19.413353",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.406097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Algorithm 1: ILGR Embedding Module\n",
    "**Input:** Graph $ G $, input node features $ X_v $ $ \\forall v \\in V $, unknown model weights $ W $ (combination weights) and $ Q $ (aggregation weights).\n",
    "\n",
    "**Output:** Nodes embedding vector $ z_v $ $ \\forall v \\in V $.\n",
    "\n",
    "**1. Initialize**: $ h^0_v = X_v $ for all $ v \\in V $.\n",
    "**2. For each layer** $ l = 1 $ to $ L $ do:\n",
    "   - For each node $ v = 1 $ to $ V $:\n",
    "     1. Compute neighborhood embedding using attention mechanism:\n",
    "        $$\n",
    "        h^l_{N(v)} = \\text{Attention}(Q^l h^{l-1}_k) \\quad \\forall k \\in N(v)\n",
    "        $$\n",
    "     2. Compute new embedding for node $ v $ using a **skip connection**:\n",
    "        $$\n",
    "        h^l_v = \\text{ReLU} \\left( W^l \\left[ h^{l-1}_v || h^{l-2}_v || h^l_{N(v)} \\right] \\right)\n",
    "        $$\n",
    "**3. Return**: Final embedding vector $ z_v = h^L_v $ for all $ v \\in V $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c1e770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.426583Z",
     "iopub.status.busy": "2025-03-20T09:59:19.426315Z",
     "iopub.status.idle": "2025-03-20T09:59:19.431402Z",
     "shell.execute_reply": "2025-03-20T09:59:19.430557Z"
    },
    "papermill": {
     "duration": 0.013195,
     "end_time": "2025-03-20T09:59:19.432663",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.419468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ILGRNodeEmbedding(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(1, hidden_channels)  # input feature: criticality \n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.attention = torch.nn.MultiheadAttention(hidden_channels, 1)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # Skip connections and attention\n",
    "        h1 = torch.relu(self.conv1(x, edge_index))\n",
    "        h2 = torch.relu(self.conv2(h1, edge_index))\n",
    "        h3 = torch.relu(self.conv3(h2, edge_index))\n",
    "        h, _ = self.attention(h3, h3, h3)\n",
    "        return torch.cat([h1, h2, h3, h], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d51998",
   "metadata": {
    "papermill": {
     "duration": 0.005963,
     "end_time": "2025-03-20T09:59:19.444654",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.438691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Regression Module\n",
    "\n",
    "The regression module applies a **non-linear transformation** using multiple layers:\n",
    "\n",
    "$$\n",
    "y_m = f(W_m \\cdot y_{m-1} + b_m)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ y_m $ is the output of the $ m^{th} $ layer.\n",
    "- $ W_m $ and $ b_m $ are the **weights** and **biases** of the $ m^{th} $ layer.\n",
    "- $ f $ is an **activation function**\n",
    "- The input to the first layer is the **node embedding**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8582c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.457712Z",
     "iopub.status.busy": "2025-03-20T09:59:19.457506Z",
     "iopub.status.idle": "2025-03-20T09:59:19.461609Z",
     "shell.execute_reply": "2025-03-20T09:59:19.460989Z"
    },
    "papermill": {
     "duration": 0.01279,
     "end_time": "2025-03-20T09:59:19.463511",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.450721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegressionModule(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cdd90",
   "metadata": {
    "papermill": {
     "duration": 0.00627,
     "end_time": "2025-03-20T09:59:19.475865",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.469595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd040fdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.489483Z",
     "iopub.status.busy": "2025-03-20T09:59:19.489146Z",
     "iopub.status.idle": "2025-03-20T09:59:19.493466Z",
     "shell.execute_reply": "2025-03-20T09:59:19.492758Z"
    },
    "papermill": {
     "duration": 0.012616,
     "end_time": "2025-03-20T09:59:19.494721",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.482105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ILGR(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.embedding = ILGRNodeEmbedding(hidden_channels)\n",
    "        self.regression = RegressionModule(hidden_channels * 4)  # Concatenated embeddings\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        embedding = self.embedding(x, edge_index)\n",
    "        return self.regression(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50a128",
   "metadata": {
    "papermill": {
     "duration": 0.006888,
     "end_time": "2025-03-20T09:59:19.507643",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.500755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Criticality Score Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d15e3",
   "metadata": {
    "papermill": {
     "duration": 0.006057,
     "end_time": "2025-03-20T09:59:19.519863",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.513806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Algorithm 3: Conventional Approach for Identifying Critical Nodes/Links\n",
    "**Input:** Graph $ G $ with $ V $ nodes.\n",
    "**Output:** Node critical scores.\n",
    "\n",
    "**1. For each node/link** $ n $ in $ V $:\n",
    "   - Remove node $ n $ from the graph $ G $.\n",
    "   - Compute robustness metric of the **residual graph** $ (G - n) $.\n",
    "   - Assign a **criticality score** to node $ n $.\n",
    "\n",
    "**2. End loop**.\n",
    "\n",
    "3. Rank nodes based on computed **criticality scores**.\n",
    "4. Top ranks correspond to the **most critical nodes**.\n",
    "**5. Return**: Top $ N\\% $ of most critical nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a8f8cf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.532912Z",
     "iopub.status.busy": "2025-03-20T09:59:19.532642Z",
     "iopub.status.idle": "2025-03-20T09:59:19.536442Z",
     "shell.execute_reply": "2025-03-20T09:59:19.535804Z"
    },
    "papermill": {
     "duration": 0.011705,
     "end_time": "2025-03-20T09:59:19.537549",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.525844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_criticality_scores(graph, metric):\n",
    "    scores = []\n",
    "    for node in tqdm(graph.nodes(), desc=\"Computing Criticality Scores\"):\n",
    "        subgraph = graph.copy()\n",
    "        subgraph.remove_node(node)\n",
    "        score = metric(graph) - metric(subgraph)  # Drop in robustness\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed5635b",
   "metadata": {
    "papermill": {
     "duration": 0.00587,
     "end_time": "2025-03-20T09:59:19.549566",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.543696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ranking Loss\n",
    "$$\n",
    "     L_{ij} = -f(r_{ij}) \\log(σ(\\hat{y}_{ij})) - (1 - f(r_{ij})) \\log(1 - σ(\\hat{y}_{ij}))\n",
    "     $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1c5b1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.562686Z",
     "iopub.status.busy": "2025-03-20T09:59:19.562424Z",
     "iopub.status.idle": "2025-03-20T09:59:19.567794Z",
     "shell.execute_reply": "2025-03-20T09:59:19.566999Z"
    },
    "papermill": {
     "duration": 0.013623,
     "end_time": "2025-03-20T09:59:19.569181",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.555558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def pairwise_ranking_loss(y_pred, y_true):\\n    # Compute all pairwise differences\\n    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # r_ij = r_i - r_j\\n    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # y_ij = y_i - y_j\\n\\n    # Apply sigmoid function to ground truth ranking differences f(r_ij)\\n    f_rij = torch.sigmoid(diff_true)\\n\\n    # Compute sigmoid of predicted ranking differences σ(ŷ_ij)\\n    sigma_y_pred = torch.sigmoid(diff_pred)\\n\\n    # Compute the pairwise ranking loss\\n    loss = -f_rij * torch.log(sigma_y_pred + 1e-10) - (1 - f_rij) * torch.log(1 - sigma_y_pred + 1e-10)\\n\\n    # Mask to consider only valid pairs (i < j) to avoid redundant comparisons\\n    mask = torch.triu(torch.ones_like(loss), diagonal=1).bool()\\n    loss = loss[mask]\\n\\n    # Compute mean loss over valid pairs\\n    return loss.mean()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def pairwise_ranking_loss(y_pred, y_true):\n",
    "    # Compute all pairwise differences\n",
    "    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # r_ij = r_i - r_j\n",
    "    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # y_ij = y_i - y_j\n",
    "\n",
    "    # Apply sigmoid function to ground truth ranking differences f(r_ij)\n",
    "    f_rij = torch.sigmoid(diff_true)\n",
    "\n",
    "    # Compute sigmoid of predicted ranking differences σ(ŷ_ij)\n",
    "    sigma_y_pred = torch.sigmoid(diff_pred)\n",
    "\n",
    "    # Compute the pairwise ranking loss\n",
    "    loss = -f_rij * torch.log(sigma_y_pred + 1e-10) - (1 - f_rij) * torch.log(1 - sigma_y_pred + 1e-10)\n",
    "\n",
    "    # Mask to consider only valid pairs (i < j) to avoid redundant comparisons\n",
    "    mask = torch.triu(torch.ones_like(loss), diagonal=1).bool()\n",
    "    loss = loss[mask]\n",
    "\n",
    "    # Compute mean loss over valid pairs\n",
    "    return loss.mean()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c63f3",
   "metadata": {
    "papermill": {
     "duration": 0.005994,
     "end_time": "2025-03-20T09:59:19.581464",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.575470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Optimize Pairwise Loss Computation\n",
    "Replace the nested-loop pairwise loss with a vectorized implementation to handle large graphs (other version of pairwise ranking loss) :\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N(N-1)/2} \\sum_{i < j} \\log \\left( 1 + \\exp \\left( - \\text{sign}(y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)}) \\cdot (y_{\\text{pred}}^{(i)} - y_{\\text{pred}}^{(j)}) \\right) \\right)\n",
    "$$\n",
    "\n",
    "### Where:\n",
    "- $ y_{\\text{pred}}^{(i)} $ and $ y_{\\text{pred}}^{(j)} $ are the predicted values for the $i$-th and $j$-th items, respectively.\n",
    "- $ y_{\\text{true}}^{(i)} $ and $ y_{\\text{true}}^{(j)} $ are the true labels for the $i$-th and $j$-th items, respectively.\n",
    "- $ \\text{sign}(x) $ is the sign function:\n",
    "- $ \\text{sign}(x) = +1 $ if $ x > 0 $\n",
    "- $ \\text{sign}(x) = -1 $ if $ x < 0 $\n",
    "\n",
    "### Breakdown:\n",
    "\n",
    "- $ y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)} $: The difference in the true values (target ranking).\n",
    "- $ y_{\\text{pred}}^{(i)} - y_{\\text{pred}}^{(j)} $: The difference in the predicted values (model's ranking).\n",
    "- $ \\text{sign}(y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)}) $ ensures that:\n",
    "- If the true ranking is correct (i.e., $ y_{\\text{true}}^{(i)} > y_{\\text{true}}^{(j)} $), we want $ y_{\\text{pred}}^{(i)} $ to be greater than $ y_{\\text{pred}}^{(j)} $.\n",
    "- The difference in predictions should match the expected order.\n",
    "\n",
    "This formulation helps enforce the correct ranking order between pairs, which is critical in learning-to-rank tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34d7e4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.594708Z",
     "iopub.status.busy": "2025-03-20T09:59:19.594467Z",
     "iopub.status.idle": "2025-03-20T09:59:19.598803Z",
     "shell.execute_reply": "2025-03-20T09:59:19.598129Z"
    },
    "papermill": {
     "duration": 0.012322,
     "end_time": "2025-03-20T09:59:19.599997",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.587675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_ranking_loss(y_pred, y_true):\n",
    "    y_pred = y_pred.squeeze()\n",
    "    y_true = y_true.squeeze()\n",
    "    \n",
    "    # Compute all pairwise differences\n",
    "    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # Shape [N, N]\n",
    "    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # Shape [N, N]\n",
    "    \n",
    "    # Mask for valid pairs (i < j)\n",
    "    mask = torch.triu(torch.ones_like(diff_true), diagonal=1).bool()\n",
    "    diff_pred = diff_pred[mask]\n",
    "    diff_true = diff_true[mask]\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = torch.log(1 + torch.exp(-torch.sign(diff_true) * diff_pred)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b02f6c",
   "metadata": {
    "papermill": {
     "duration": 0.006234,
     "end_time": "2025-03-20T09:59:19.612293",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.606059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Graph Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b4205b",
   "metadata": {
    "papermill": {
     "duration": 0.006599,
     "end_time": "2025-03-20T09:59:19.624953",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.618354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate Synthetic Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2768b312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.638104Z",
     "iopub.status.busy": "2025-03-20T09:59:19.637878Z",
     "iopub.status.idle": "2025-03-20T09:59:19.641465Z",
     "shell.execute_reply": "2025-03-20T09:59:19.640691Z"
    },
    "papermill": {
     "duration": 0.011626,
     "end_time": "2025-03-20T09:59:19.642681",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.631055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Power-law graph (Barabási-Albert model)\n",
    "def generate_power_law(n, m):\n",
    "    return nx.barabasi_albert_graph(n, m)\n",
    "\n",
    "# Power-law cluster graph (Holme-Kim model)\n",
    "def generate_power_law_cluster(n, m, p):\n",
    "    return nx.powerlaw_cluster_graph(n, m, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbfde7",
   "metadata": {
    "papermill": {
     "duration": 0.005937,
     "end_time": "2025-03-20T09:59:19.654651",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.648714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### real-world datasets (load function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe3f4b44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.667611Z",
     "iopub.status.busy": "2025-03-20T09:59:19.667410Z",
     "iopub.status.idle": "2025-03-20T09:59:19.670616Z",
     "shell.execute_reply": "2025-03-20T09:59:19.669887Z"
    },
    "papermill": {
     "duration": 0.011153,
     "end_time": "2025-03-20T09:59:19.671841",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.660688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_real_world_graph(dataset_name):\n",
    "    G = nx.read_edgelist(dataset_name, nodetype=int)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84626e2b",
   "metadata": {
    "papermill": {
     "duration": 0.005999,
     "end_time": "2025-03-20T09:59:19.684001",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.678002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert NetworkX graph to PyTorch Geometric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e80393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.697020Z",
     "iopub.status.busy": "2025-03-20T09:59:19.696813Z",
     "iopub.status.idle": "2025-03-20T09:59:19.700026Z",
     "shell.execute_reply": "2025-03-20T09:59:19.699428Z"
    },
    "papermill": {
     "duration": 0.011014,
     "end_time": "2025-03-20T09:59:19.701101",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.690087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nx_to_pyg(nx_graph, criticality_scores):\n",
    "    # Convert NetworkX graph to PyG format\n",
    "    pyg_data = from_networkx(nx_graph)\n",
    "\n",
    "    # Use criticality scores as node features\n",
    "    pyg_data.x = criticality_scores.view(-1, 1)\n",
    "\n",
    "    return pyg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9787b",
   "metadata": {
    "papermill": {
     "duration": 0.00604,
     "end_time": "2025-03-20T09:59:19.713306",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.707266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Algorithm 2: ILGR Training\n",
    "**Input:** Model with unknown weights.\n",
    "**Output:** Trained model.\n",
    "\n",
    "1. Compute ground truth **criticality scores** of nodes based on graph robustness score.\n",
    "2. **For each epoch do**:\n",
    "   - Get each **node embedding** from the embedding module.\n",
    "   - Estimate **criticality scores** of nodes/links using the regression module.\n",
    "   - Update weights of both modules by solving the loss function:\n",
    "     $$\n",
    "     L_{ij} = -f(r_{ij}) \\log(σ(\\hat{y}_{ij})) - (1 - f(r_{ij})) \\log(1 - σ(\\hat{y}_{ij}))\n",
    "     $$\n",
    "3. **End loop**.\n",
    "4. Predict nodescores on the test graph.\n",
    "5. **Return**: Top $ N\\% $ of most critical nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ed4c6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.726391Z",
     "iopub.status.busy": "2025-03-20T09:59:19.726150Z",
     "iopub.status.idle": "2025-03-20T09:59:19.730874Z",
     "shell.execute_reply": "2025-03-20T09:59:19.730046Z"
    },
    "papermill": {
     "duration": 0.012845,
     "end_time": "2025-03-20T09:59:19.732229",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.719384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, data, y_true, epochs=100, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    data, y_true = data.to(device), y_true.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    progress_bar = tqdm(range(epochs), desc=\"Training Model\", dynamic_ncols=True)\n",
    "    \n",
    "    for epoch in progress_bar:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(data)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = pairwise_ranking_loss(y_pred, y_true)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar with loss value\n",
    "        progress_bar.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ad54b",
   "metadata": {
    "papermill": {
     "duration": 0.006525,
     "end_time": "2025-03-20T09:59:19.744999",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.738474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Evaluation Metrics: Top-N% Accuracy**\n",
    "\n",
    "To measure the accuracy of our framework, we use **Top-N% Accuracy**, which is defined as the percentage of overlap between the predicted Top-N% nodes/links and the ground-truth Top-N% nodes/links (computed using a conventional baseline approach). \n",
    "\n",
    "The formula for **Top-N% Accuracy** is given by:\n",
    "\n",
    "$$\n",
    "\\text{Top-N% Accuracy} = \\frac{\\left| \\{\\text{Predicted Top-N% nodes/links}\\} \\cap \\{\\text{True Top-N% nodes/links}\\} \\right|}{|V| \\times (N/100)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ |V| $ is the total number of nodes/links in the graph.\n",
    "- $ N $ is the percentage band (e.g., Top-5%).\n",
    "- $ \\cap $ denotes the intersection between the predicted and true Top-N% sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d79b9d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.758397Z",
     "iopub.status.busy": "2025-03-20T09:59:19.758114Z",
     "iopub.status.idle": "2025-03-20T09:59:19.762188Z",
     "shell.execute_reply": "2025-03-20T09:59:19.761561Z"
    },
    "papermill": {
     "duration": 0.011993,
     "end_time": "2025-03-20T09:59:19.763368",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.751375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_n_accuracy(y_pred, y_true, N=5):\n",
    "    num_nodes = len(y_true)\n",
    "    top_n = int(num_nodes * (N / 100))\n",
    "\n",
    "    # Get indices of top N% nodes for predicted and true values\n",
    "    top_pred = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "    top_true = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "    # Compute accuracy as percentage of overlap\n",
    "    accuracy = len(set(top_pred.tolist()) & set(top_true.tolist())) / top_n\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d62970",
   "metadata": {
    "papermill": {
     "duration": 0.006089,
     "end_time": "2025-03-20T09:59:19.775673",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.769584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Test the framwork**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9e947",
   "metadata": {
    "papermill": {
     "duration": 0.005982,
     "end_time": "2025-03-20T09:59:19.787729",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.781747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1000 nodes (power-law graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5055c31b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:59:19.801098Z",
     "iopub.status.busy": "2025-03-20T09:59:19.800836Z",
     "iopub.status.idle": "2025-03-20T10:03:02.660478Z",
     "shell.execute_reply": "2025-03-20T10:03:02.659507Z"
    },
    "papermill": {
     "duration": 222.867912,
     "end_time": "2025-03-20T10:03:02.661777",
     "exception": false,
     "start_time": "2025-03-20T09:59:19.793865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1000/1000 [03:34<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILGR(\n",
      "  (embedding): ILGRNodeEmbedding(\n",
      "    (conv1): SAGEConv(1, 32, aggr=mean)\n",
      "    (conv2): SAGEConv(32, 32, aggr=mean)\n",
      "    (conv3): SAGEConv(32, 32, aggr=mean)\n",
      "    (attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (regression): RegressionModule(\n",
      "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 1000/1000 [00:08<00:00, 124.36it/s, loss=0.00422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Top-5% True Node Indices: [68, 890, 573, 731, 55, 544, 19, 102, 712, 146, 28, 301, 446, 720, 381, 729, 11, 4, 25, 17, 411, 10, 369, 64, 89, 152, 233, 261, 409, 8, 258, 279, 217, 90, 186, 128, 92, 3, 12, 2, 32, 191, 917, 560, 39, 242, 127, 559, 870, 331]\n",
      "Top-5% Predicted Node Indices: [68, 890, 573, 731, 55, 544, 19, 102, 712, 146, 28, 301, 446, 720, 381, 729, 11, 4, 25, 17, 411, 10, 369, 64, 89, 152, 233, 261, 409, 8, 258, 279, 217, 90, 186, 128, 92, 3, 12, 2, 32, 191, 917, 560, 39, 242, 127, 559, 870, 331]\n",
      "Top-5% Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate a power-law graph\n",
    "G = generate_power_law(n=1000, m=3)\n",
    "\n",
    "# Step 2: Compute criticality scores\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Step 3: Convert to PyG format with node features\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "# Step 4: Define the model\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "print(model)\n",
    "\n",
    "# Step 5: Train the model\n",
    "train_model(model, data, y_true, epochs=1000, lr=0.001)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(data).detach()  # Ensure no gradients\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model_pl.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Evaluate the top-N% nodes based on their criticality scores (true values)\n",
    "top_n = int(len(y_true) * 0.05)  # Top 5% nodes\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Display top-5% criticality scores for both true and predicted values\n",
    "# print(\"Top-5% True Criticality Scores:\", y_true[top_n_true_indices].tolist())\n",
    "# print(\"Top-5% Predicted Criticality Scores:\", y_pred[top_n_pred_indices].tolist())\n",
    "\n",
    "\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b269a",
   "metadata": {
    "papermill": {
     "duration": 0.096682,
     "end_time": "2025-03-20T10:03:02.896345",
     "exception": false,
     "start_time": "2025-03-20T10:03:02.799663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1000 nodes (power-law cluster graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "095a239a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:03:03.089734Z",
     "iopub.status.busy": "2025-03-20T10:03:03.089410Z",
     "iopub.status.idle": "2025-03-20T10:06:43.650889Z",
     "shell.execute_reply": "2025-03-20T10:06:43.649896Z"
    },
    "papermill": {
     "duration": 220.658391,
     "end_time": "2025-03-20T10:06:43.652239",
     "exception": false,
     "start_time": "2025-03-20T10:03:02.993848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1000/1000 [03:33<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILGR(\n",
      "  (embedding): ILGRNodeEmbedding(\n",
      "    (conv1): SAGEConv(1, 32, aggr=mean)\n",
      "    (conv2): SAGEConv(32, 32, aggr=mean)\n",
      "    (conv3): SAGEConv(32, 32, aggr=mean)\n",
      "    (attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (regression): RegressionModule(\n",
      "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 1000/1000 [00:06<00:00, 143.02it/s, loss=0.00224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Top-5% True Node Indices: [557, 570, 707, 749, 432, 466, 684, 589, 100, 672, 404, 674, 829, 492, 446, 632, 983, 818, 914, 464, 590, 228, 799, 912, 105, 289, 239, 595, 904, 886, 162, 591, 792, 476, 298, 299, 393, 809, 236, 918, 567, 816, 39, 249, 917, 47, 676, 207, 284, 338]\n",
      "Top-5% Predicted Node Indices: [557, 570, 707, 749, 432, 466, 684, 589, 100, 672, 404, 674, 829, 492, 446, 632, 983, 818, 914, 464, 590, 228, 799, 912, 105, 289, 239, 595, 904, 162, 886, 591, 476, 792, 298, 299, 393, 809, 236, 918, 567, 816, 39, 249, 917, 47, 676, 207, 284, 338]\n",
      "Top-5% Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate a power-law graph cluster\n",
    "G = generate_power_law_cluster(n=1000, m=3, p=0.3)\n",
    "\n",
    "# Step 2: Compute criticality scores\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Step 3: Convert to PyG format with node features\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "# Step 4: Define the model\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "print(model)\n",
    "\n",
    "# Step 5: Train the model\n",
    "train_model(model, data, y_true, epochs=1000, lr=0.001)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(data).detach()  # Ensure no gradients\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model_plc.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "\n",
    "# Evaluate the top-N% nodes based on their criticality scores (true values)\n",
    "top_n = int(len(y_true) * 0.05)  # Top 5% nodes\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Display top-5% criticality scores for both true and predicted values\n",
    "# print(\"Top-5% True Criticality Scores:\", y_true[top_n_true_indices].tolist())\n",
    "# print(\"Top-5% Predicted Criticality Scores:\", y_pred[top_n_pred_indices].tolist())\n",
    "\n",
    "\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064e1670",
   "metadata": {
    "papermill": {
     "duration": 0.188032,
     "end_time": "2025-03-20T10:06:44.036795",
     "exception": false,
     "start_time": "2025-03-20T10:06:43.848763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bio Yeast Dataset (power_law_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60972386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:06:44.419516Z",
     "iopub.status.busy": "2025-03-20T10:06:44.419144Z",
     "iopub.status.idle": "2025-03-20T10:18:50.980815Z",
     "shell.execute_reply": "2025-03-20T10:18:50.979952Z"
    },
    "papermill": {
     "duration": 726.756265,
     "end_time": "2025-03-20T10:18:50.982113",
     "exception": false,
     "start_time": "2025-03-20T10:06:44.225848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1458/1458 [12:06<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Bio Yeast graph with 1458 nodes and 1948 edges.\n",
      "Model loaded successfully!\n",
      "Top-5% True Node Indices: [542, 1078, 949, 640, 787, 81, 285, 714, 88, 725, 797, 829, 91, 964, 943, 1032, 645, 888, 1, 595, 155, 278, 368, 982, 996, 458, 417, 196, 268, 1027, 1085, 428, 702, 473, 908, 963, 766, 669, 567, 6, 1140, 984, 393, 869, 242, 1043, 937, 560, 406, 398, 63, 2, 850, 30, 1025, 56, 109, 1400, 484, 250, 1114, 890, 1126, 1409, 379, 31, 929, 1115, 517, 251, 201, 1440]\n",
      "Top-5% Predicted Node Indices: [936, 1437, 1081, 989, 348, 439, 481, 1147, 804, 781, 1348, 1347, 25, 291, 1151, 386, 1421, 709, 76, 640, 1078, 949, 542, 88, 81, 787, 194, 1030, 245, 676, 1048, 1021, 623, 917, 176, 796, 1006, 998, 991, 134, 980, 977, 740, 116, 100, 762, 896, 299, 556, 909, 546, 543, 1096, 530, 839, 311, 1108, 851, 479, 477, 446, 1152, 1168, 298, 41, 1057, 906, 39, 588, 33, 294, 296]\n",
      "Top-5% Accuracy: 9.72%\n"
     ]
    }
   ],
   "source": [
    "# Load the Matrix Market file (Bio Yeast graph)\n",
    "file_path = \"/kaggle/input/bio-yeast/bio-yeast.mtx\"\n",
    "matrix = mmread(file_path)\n",
    "\n",
    "# Convert to a NetworkX graph\n",
    "# Use the appropriate function based on your NetworkX version\n",
    "try:\n",
    "    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\n",
    "except AttributeError:\n",
    "    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n",
    "\n",
    "# Compute criticality scores (assuming your function is defined)\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Convert to PyG format\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "print(f\"Loaded Bio Yeast graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "# Define model architecture (must match saved model)\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\", weights_only=True))\n",
    "model.eval()  # Set to evaluation model\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model(data).detach()\n",
    "\n",
    "# Evaluate Top-5% Nodes\n",
    "top_n = int(len(y_true) * 0.05)\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist()) \n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Compute Top-5% Accuracy\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b67254d",
   "metadata": {
    "papermill": {
     "duration": 0.301,
     "end_time": "2025-03-20T10:18:51.543102",
     "exception": false,
     "start_time": "2025-03-20T10:18:51.242102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bio Yeast Dataset (power_law_cluster_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bbf9b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:18:52.048356Z",
     "iopub.status.busy": "2025-03-20T10:18:52.048024Z",
     "iopub.status.idle": "2025-03-20T10:29:29.552078Z",
     "shell.execute_reply": "2025-03-20T10:29:29.550803Z"
    },
    "papermill": {
     "duration": 637.759535,
     "end_time": "2025-03-20T10:29:29.553973",
     "exception": false,
     "start_time": "2025-03-20T10:18:51.794438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1458/1458 [10:37<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Bio Yeast graph with 1458 nodes and 1948 edges.\n",
      "Model loaded successfully!\n",
      "Top-5% True Node Indices: [542, 1078, 949, 640, 787, 81, 285, 714, 88, 725, 797, 829, 91, 964, 943, 1032, 645, 888, 1, 595, 155, 278, 368, 982, 996, 458, 417, 196, 268, 1027, 1085, 428, 702, 473, 908, 963, 766, 669, 567, 6, 1140, 984, 393, 869, 242, 1043, 937, 560, 406, 398, 63, 2, 850, 30, 1025, 56, 109, 1400, 484, 250, 1114, 890, 1126, 1409, 379, 31, 929, 1115, 517, 251, 201, 1440]\n",
      "Top-5% Predicted Node Indices: [640, 1078, 285, 714, 542, 949, 81, 787, 88, 91, 829, 595, 645, 1032, 1, 155, 1027, 908, 888, 368, 196, 428, 458, 797, 725, 964, 1085, 996, 963, 766, 702, 6, 1140, 2, 943, 1043, 560, 937, 982, 398, 406, 268, 869, 278, 484, 379, 31, 393, 567, 1440, 1400, 687, 1126, 1387, 1409, 517, 557, 958, 438, 417, 1402, 769, 984, 421, 669, 1115, 1127, 30, 50, 1232, 126, 1435]\n",
      "Top-5% Accuracy: 81.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Matrix Market file (Bio Yeast graph)\n",
    "file_path = \"/kaggle/input/bio-yeast/bio-yeast.mtx\"\n",
    "matrix = mmread(file_path)\n",
    "\n",
    "# Convert to a NetworkX graph\n",
    "# Use the appropriate function based on your NetworkX version\n",
    "try:\n",
    "    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\n",
    "except AttributeError:\n",
    "    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n",
    "\n",
    "# Compute criticality scores (assuming your function is defined)\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Convert to PyG format\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "print(f\"Loaded Bio Yeast graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "# Define model architecture (must match saved model)\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/trained_model_plc.pth\", weights_only=True))\n",
    "model.eval()  # Set to evaluation model\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model(data).detach()\n",
    "\n",
    "# Evaluate Top-5% Nodes\n",
    "top_n = int(len(y_true) * 0.05)\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist()) \n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Compute Top-5% Accuracy\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f01355c",
   "metadata": {
    "papermill": {
     "duration": 0.321725,
     "end_time": "2025-03-20T10:29:30.254361",
     "exception": false,
     "start_time": "2025-03-20T10:29:29.932636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### US Power Grid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "010bb6ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:29:30.900405Z",
     "iopub.status.busy": "2025-03-20T10:29:30.900042Z",
     "iopub.status.idle": "2025-03-20T10:29:30.905314Z",
     "shell.execute_reply": "2025-03-20T10:29:30.904631Z"
    },
    "papermill": {
     "duration": 0.331166,
     "end_time": "2025-03-20T10:29:30.906466",
     "exception": false,
     "start_time": "2025-03-20T10:29:30.575300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load the Matrix Market file (US Power Grid graph)\\nfile_path = \"/kaggle/input/power-us-grid/power-US-Grid.mtx\"\\nmatrix = mmread(file_path)\\n\\n# Convert to a NetworkX graph\\n# Use the appropriate function based on your NetworkX version\\ntry:\\n    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\\nexcept AttributeError:\\n    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\\n\\n# Compute criticality scores (assuming your function is defined)\\ny_true = compute_criticality_scores(G, compute_effective_resistance)\\ny_true = torch.tensor(y_true, dtype=torch.float)\\n\\n# Convert to PyG format\\ndata = nx_to_pyg(G, y_true)\\n\\nprint(f\"Loaded US Power Grid graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\\n\\n# Define model architecture (must match saved model)\\nhidden_dim = 32\\nmodel = ILGR(hidden_dim)\\n\\n# Load trained weights\\nmodel.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\"))\\nmodel.eval()  # Set to evaluation model\\nprint(\"Model loaded successfully!\")\\n\\n# Make predictions\\ny_pred = model(data).detach()\\n\\n# Evaluate Top-5% Nodes\\ntop_n = int(len(y_true) * 0.05)\\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\\n\\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\\nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\\n\\n# Compute Top-5% Accuracy\\naccuracy = top_n_accuracy(y_pred, y_true, N=5)\\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Load the Matrix Market file (US Power Grid graph)\n",
    "file_path = \"/kaggle/input/power-us-grid/power-US-Grid.mtx\"\n",
    "matrix = mmread(file_path)\n",
    "\n",
    "# Convert to a NetworkX graph\n",
    "# Use the appropriate function based on your NetworkX version\n",
    "try:\n",
    "    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\n",
    "except AttributeError:\n",
    "    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n",
    "\n",
    "# Compute criticality scores (assuming your function is defined)\n",
    "y_true = compute_criticality_scores(G, compute_effective_resistance)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Convert to PyG format\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "print(f\"Loaded US Power Grid graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "# Define model architecture (must match saved model)\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\"))\n",
    "model.eval()  # Set to evaluation model\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model(data).detach()\n",
    "\n",
    "# Evaluate Top-5% Nodes\n",
    "top_n = int(len(y_true) * 0.05)\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Compute Top-5% Accuracy\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d396700",
   "metadata": {
    "papermill": {
     "duration": 0.320909,
     "end_time": "2025-03-20T10:29:31.598053",
     "exception": false,
     "start_time": "2025-03-20T10:29:31.277144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6910282,
     "sourceId": 11086795,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6911061,
     "sourceId": 11087843,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1836.288028,
   "end_time": "2025-03-20T10:29:34.827101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-20T09:58:58.539073",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
