{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11086795,"sourceType":"datasetVersion","datasetId":6910282},{"sourceId":11087843,"sourceType":"datasetVersion","datasetId":6911061}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-geometric -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:08:57.272665Z","iopub.execute_input":"2025-03-20T09:08:57.273038Z","iopub.status.idle":"2025-03-20T09:09:00.610199Z","shell.execute_reply.started":"2025-03-20T09:08:57.272994Z","shell.execute_reply":"2025-03-20T09:09:00.609022Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch_geometric.nn import SAGEConv\nfrom torch_geometric.data import Data\nimport torch.nn.functional as F\nimport networkx as nx\nfrom torch_geometric.utils import from_networkx\nfrom torch_geometric.utils.convert import from_networkx\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom scipy.io import mmread","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.611629Z","iopub.execute_input":"2025-03-20T09:09:00.611932Z","iopub.status.idle":"2025-03-20T09:09:00.617011Z","shell.execute_reply.started":"2025-03-20T09:09:00.611908Z","shell.execute_reply":"2025-03-20T09:09:00.616240Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Graph Robustness Metrics","metadata":{}},{"cell_type":"markdown","source":"**1. Effective Graph Resistance (EGR)**  \n   $$\n   R_g = \\frac{2}{N-1} \\sum_{i=1}^{N-c} \\frac{1}{\\lambda_i}\n   $$\n   where $ \\lambda_i $ are the eigenvalues of the Laplacian matrix of the graph.","metadata":{}},{"cell_type":"code","source":"def compute_effective_resistance(graph):\n    laplacian = nx.laplacian_matrix(graph).toarray()\n    eigenvalues = np.linalg.eigvalsh(laplacian)\n    eigenvalues = eigenvalues[eigenvalues > 1e-8]  # Avoid zero eigenvalues\n    N = graph.number_of_nodes()\n    return (2 / (N - 1)) * np.sum(1 / eigenvalues)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.618684Z","iopub.execute_input":"2025-03-20T09:09:00.618956Z","iopub.status.idle":"2025-03-20T09:09:00.630094Z","shell.execute_reply.started":"2025-03-20T09:09:00.618936Z","shell.execute_reply":"2025-03-20T09:09:00.629291Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"**2. Weighted Spectrum (WS)**  \n   $$\n   W_s = \\sum_i (1 - \\lambda_i)^n\n   $$\n   where $ n $ controls the depth of analysis","metadata":{}},{"cell_type":"code","source":"def compute_weighted_spectrum(graph, n=3):\n    laplacian = nx.normalized_laplacian_matrix(graph).toarray()\n    eigenvalues = np.linalg.eigvalsh(laplacian)\n    return np.sum((1 - eigenvalues) ** n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.631391Z","iopub.execute_input":"2025-03-20T09:09:00.631610Z","iopub.status.idle":"2025-03-20T09:09:00.640073Z","shell.execute_reply.started":"2025-03-20T09:09:00.631592Z","shell.execute_reply":"2025-03-20T09:09:00.639240Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Algorithm 1: ILGR Embedding Module\n**Input:** Graph $ G $, input node features $ X_v $ $ \\forall v \\in V $, unknown model weights $ W $ (combination weights) and $ Q $ (aggregation weights).\n\n**Output:** Nodes embedding vector $ z_v $ $ \\forall v \\in V $.\n\n**1. Initialize**: $ h^0_v = X_v $ for all $ v \\in V $.\n**2. For each layer** $ l = 1 $ to $ L $ do:\n   - For each node $ v = 1 $ to $ V $:\n     1. Compute neighborhood embedding using attention mechanism:\n        $$\n        h^l_{N(v)} = \\text{Attention}(Q^l h^{l-1}_k) \\quad \\forall k \\in N(v)\n        $$\n     2. Compute new embedding for node $ v $ using a **skip connection**:\n        $$\n        h^l_v = \\text{ReLU} \\left( W^l \\left[ h^{l-1}_v || h^{l-2}_v || h^l_{N(v)} \\right] \\right)\n        $$\n**3. Return**: Final embedding vector $ z_v = h^L_v $ for all $ v \\in V $.\n","metadata":{}},{"cell_type":"code","source":"class ILGRNodeEmbedding(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        self.conv1 = SAGEConv(1, hidden_channels)  # input feature: criticality \n        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n        self.attention = torch.nn.MultiheadAttention(hidden_channels, 1)\n        \n    def forward(self, x, edge_index):\n        # Skip connections and attention\n        h1 = torch.relu(self.conv1(x, edge_index))\n        h2 = torch.relu(self.conv2(h1, edge_index))\n        h3 = torch.relu(self.conv3(h2, edge_index))\n        h, _ = self.attention(h3, h3, h3)\n        return torch.cat([h1, h2, h3, h], dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.640919Z","iopub.execute_input":"2025-03-20T09:09:00.641192Z","iopub.status.idle":"2025-03-20T09:09:00.648464Z","shell.execute_reply.started":"2025-03-20T09:09:00.641172Z","shell.execute_reply":"2025-03-20T09:09:00.647779Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Regression Module\n\nThe regression module applies a **non-linear transformation** using multiple layers:\n\n$$\ny_m = f(W_m \\cdot y_{m-1} + b_m)\n$$\n\nwhere:\n- $ y_m $ is the output of the $ m^{th} $ layer.\n- $ W_m $ and $ b_m $ are the **weights** and **biases** of the $ m^{th} $ layer.\n- $ f $ is an **activation function**\n- The input to the first layer is the **node embedding**:\n\n","metadata":{}},{"cell_type":"code","source":"class RegressionModule(torch.nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc1 = torch.nn.Linear(input_dim, 64)\n        self.fc2 = torch.nn.Linear(64, 32)\n        self.fc3 = torch.nn.Linear(32, 1)\n        \n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        return self.fc3(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.649256Z","iopub.execute_input":"2025-03-20T09:09:00.649510Z","iopub.status.idle":"2025-03-20T09:09:00.661074Z","shell.execute_reply.started":"2025-03-20T09:09:00.649480Z","shell.execute_reply":"2025-03-20T09:09:00.660317Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## Full Model","metadata":{}},{"cell_type":"code","source":"class ILGR(torch.nn.Module):\n    def __init__(self, hidden_channels):\n        super().__init__()\n        self.embedding = ILGRNodeEmbedding(hidden_channels)\n        self.regression = RegressionModule(hidden_channels * 4)  # Concatenated embeddings\n        \n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        embedding = self.embedding(x, edge_index)\n        return self.regression(embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.661968Z","iopub.execute_input":"2025-03-20T09:09:00.662193Z","iopub.status.idle":"2025-03-20T09:09:00.673976Z","shell.execute_reply.started":"2025-03-20T09:09:00.662175Z","shell.execute_reply":"2025-03-20T09:09:00.673302Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"### Criticality Score Calculation","metadata":{}},{"cell_type":"markdown","source":"### Algorithm 3: Conventional Approach for Identifying Critical Nodes/Links\n**Input:** Graph $ G $ with $ V $ nodes.\n**Output:** Node critical scores.\n\n**1. For each node/link** $ n $ in $ V $:\n   - Remove node $ n $ from the graph $ G $.\n   - Compute robustness metric of the **residual graph** $ (G - n) $.\n   - Assign a **criticality score** to node $ n $.\n\n**2. End loop**.\n\n3. Rank nodes based on computed **criticality scores**.\n4. Top ranks correspond to the **most critical nodes**.\n**5. Return**: Top $ N\\% $ of most critical nodes.","metadata":{}},{"cell_type":"code","source":"def compute_criticality_scores(graph, metric):\n    scores = []\n    for node in tqdm(graph.nodes(), desc=\"Computing Criticality Scores\"):\n        subgraph = graph.copy()\n        subgraph.remove_node(node)\n        score = metric(graph) - metric(subgraph)  # Drop in robustness\n        scores.append(score)\n    return scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.676119Z","iopub.execute_input":"2025-03-20T09:09:00.676319Z","iopub.status.idle":"2025-03-20T09:09:00.690427Z","shell.execute_reply.started":"2025-03-20T09:09:00.676302Z","shell.execute_reply":"2025-03-20T09:09:00.689767Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"### Ranking Loss\n$$\n     L_{ij} = -f(r_{ij}) \\log(σ(\\hat{y}_{ij})) - (1 - f(r_{ij})) \\log(1 - σ(\\hat{y}_{ij}))\n     $$","metadata":{}},{"cell_type":"code","source":"\"\"\"def pairwise_ranking_loss(y_pred, y_true):\n    # Compute all pairwise differences\n    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # r_ij = r_i - r_j\n    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # y_ij = y_i - y_j\n\n    # Apply sigmoid function to ground truth ranking differences f(r_ij)\n    f_rij = torch.sigmoid(diff_true)\n\n    # Compute sigmoid of predicted ranking differences σ(ŷ_ij)\n    sigma_y_pred = torch.sigmoid(diff_pred)\n\n    # Compute the pairwise ranking loss\n    loss = -f_rij * torch.log(sigma_y_pred + 1e-10) - (1 - f_rij) * torch.log(1 - sigma_y_pred + 1e-10)\n\n    # Mask to consider only valid pairs (i < j) to avoid redundant comparisons\n    mask = torch.triu(torch.ones_like(loss), diagonal=1).bool()\n    loss = loss[mask]\n\n    # Compute mean loss over valid pairs\n    return loss.mean()\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.691599Z","iopub.execute_input":"2025-03-20T09:09:00.691817Z","iopub.status.idle":"2025-03-20T09:09:00.702757Z","shell.execute_reply.started":"2025-03-20T09:09:00.691798Z","shell.execute_reply":"2025-03-20T09:09:00.701858Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'def pairwise_ranking_loss(y_pred, y_true):\\n    # Compute all pairwise differences\\n    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # r_ij = r_i - r_j\\n    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # y_ij = y_i - y_j\\n\\n    # Apply sigmoid function to ground truth ranking differences f(r_ij)\\n    f_rij = torch.sigmoid(diff_true)\\n\\n    # Compute sigmoid of predicted ranking differences σ(ŷ_ij)\\n    sigma_y_pred = torch.sigmoid(diff_pred)\\n\\n    # Compute the pairwise ranking loss\\n    loss = -f_rij * torch.log(sigma_y_pred + 1e-10) - (1 - f_rij) * torch.log(1 - sigma_y_pred + 1e-10)\\n\\n    # Mask to consider only valid pairs (i < j) to avoid redundant comparisons\\n    mask = torch.triu(torch.ones_like(loss), diagonal=1).bool()\\n    loss = loss[mask]\\n\\n    # Compute mean loss over valid pairs\\n    return loss.mean()'"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"### Optimize Pairwise Loss Computation\nReplace the nested-loop pairwise loss with a vectorized implementation to handle large graphs (other version of pairwise ranking loss) :\n\n$$\nL = \\frac{1}{N(N-1)/2} \\sum_{i < j} \\log \\left( 1 + \\exp \\left( - \\text{sign}(y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)}) \\cdot (y_{\\text{pred}}^{(i)} - y_{\\text{pred}}^{(j)}) \\right) \\right)\n$$\n\n### Where:\n- $ y_{\\text{pred}}^{(i)} $ and $ y_{\\text{pred}}^{(j)} $ are the predicted values for the $i$-th and $j$-th items, respectively.\n- $ y_{\\text{true}}^{(i)} $ and $ y_{\\text{true}}^{(j)} $ are the true labels for the $i$-th and $j$-th items, respectively.\n- $ \\text{sign}(x) $ is the sign function:\n- $ \\text{sign}(x) = +1 $ if $ x > 0 $\n- $ \\text{sign}(x) = -1 $ if $ x < 0 $\n\n### Breakdown:\n\n- $ y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)} $: The difference in the true values (target ranking).\n- $ y_{\\text{pred}}^{(i)} - y_{\\text{pred}}^{(j)} $: The difference in the predicted values (model's ranking).\n- $ \\text{sign}(y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)}) $ ensures that:\n- If the true ranking is correct (i.e., $ y_{\\text{true}}^{(i)} > y_{\\text{true}}^{(j)} $), we want $ y_{\\text{pred}}^{(i)} $ to be greater than $ y_{\\text{pred}}^{(j)} $.\n- The difference in predictions should match the expected order.\n\nThis formulation helps enforce the correct ranking order between pairs, which is critical in learning-to-rank tasks.\n","metadata":{}},{"cell_type":"code","source":"def pairwise_ranking_loss(y_pred, y_true):\n    y_pred = y_pred.squeeze()\n    y_true = y_true.squeeze()\n    \n    # Compute all pairwise differences\n    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # Shape [N, N]\n    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # Shape [N, N]\n    \n    # Mask for valid pairs (i < j)\n    mask = torch.triu(torch.ones_like(diff_true), diagonal=1).bool()\n    diff_pred = diff_pred[mask]\n    diff_true = diff_true[mask]\n    \n    # Compute loss\n    loss = torch.log(1 + torch.exp(-torch.sign(diff_true) * diff_pred)).mean()\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.703594Z","iopub.execute_input":"2025-03-20T09:09:00.703809Z","iopub.status.idle":"2025-03-20T09:09:00.713422Z","shell.execute_reply.started":"2025-03-20T09:09:00.703791Z","shell.execute_reply":"2025-03-20T09:09:00.712754Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## Graph Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Generate Synthetic Graphs","metadata":{}},{"cell_type":"code","source":"# Power-law graph (Barabási-Albert model)\ndef generate_power_law(n, m):\n    return nx.barabasi_albert_graph(n, m)\n\n# Power-law cluster graph (Holme-Kim model)\ndef generate_power_law_cluster(n, m, p):\n    return nx.powerlaw_cluster_graph(n, m, p)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.714146Z","iopub.execute_input":"2025-03-20T09:09:00.714330Z","iopub.status.idle":"2025-03-20T09:09:00.726791Z","shell.execute_reply.started":"2025-03-20T09:09:00.714314Z","shell.execute_reply":"2025-03-20T09:09:00.726164Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"### real-world datasets (load function)","metadata":{}},{"cell_type":"code","source":"def load_real_world_graph(dataset_name):\n    G = nx.read_edgelist(dataset_name, nodetype=int)\n    return G","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.727494Z","iopub.execute_input":"2025-03-20T09:09:00.727715Z","iopub.status.idle":"2025-03-20T09:09:00.736672Z","shell.execute_reply.started":"2025-03-20T09:09:00.727697Z","shell.execute_reply":"2025-03-20T09:09:00.736006Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"### Convert NetworkX graph to PyTorch Geometric format","metadata":{}},{"cell_type":"code","source":"def nx_to_pyg(nx_graph, criticality_scores):\n    # Convert NetworkX graph to PyG format\n    pyg_data = from_networkx(nx_graph)\n\n    # Use criticality scores as node features\n    pyg_data.x = criticality_scores.view(-1, 1)\n\n    return pyg_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.737297Z","iopub.execute_input":"2025-03-20T09:09:00.737486Z","iopub.status.idle":"2025-03-20T09:09:00.743441Z","shell.execute_reply.started":"2025-03-20T09:09:00.737470Z","shell.execute_reply":"2025-03-20T09:09:00.742752Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"## Algorithm 2: ILGR Training\n**Input:** Model with unknown weights.\n**Output:** Trained model.\n\n1. Compute ground truth **criticality scores** of nodes based on graph robustness score.\n2. **For each epoch do**:\n   - Get each **node embedding** from the embedding module.\n   - Estimate **criticality scores** of nodes/links using the regression module.\n   - Update weights of both modules by solving the loss function:\n     $$\n     L_{ij} = -f(r_{ij}) \\log(σ(\\hat{y}_{ij})) - (1 - f(r_{ij})) \\log(1 - σ(\\hat{y}_{ij}))\n     $$\n3. **End loop**.\n4. Predict nodescores on the test graph.\n5. **Return**: Top $ N\\% $ of most critical nodes.\n","metadata":{}},{"cell_type":"code","source":"def train_model(model, data, y_true, epochs=100, lr=0.001):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    data, y_true = data.to(device), y_true.to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    progress_bar = tqdm(range(epochs), desc=\"Training Model\", dynamic_ncols=True)\n    \n    for epoch in progress_bar:\n        model.train()\n        optimizer.zero_grad()\n\n        # Forward pass\n        y_pred = model(data)\n\n        # Compute loss\n        loss = pairwise_ranking_loss(y_pred, y_true)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        \n        # Update progress bar with loss value\n        progress_bar.set_postfix(loss=loss.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.744155Z","iopub.execute_input":"2025-03-20T09:09:00.744439Z","iopub.status.idle":"2025-03-20T09:09:00.755775Z","shell.execute_reply.started":"2025-03-20T09:09:00.744420Z","shell.execute_reply":"2025-03-20T09:09:00.755069Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"### **Evaluation Metrics: Top-N% Accuracy**\n\nTo measure the accuracy of our framework, we use **Top-N% Accuracy**, which is defined as the percentage of overlap between the predicted Top-N% nodes/links and the ground-truth Top-N% nodes/links (computed using a conventional baseline approach). \n\nThe formula for **Top-N% Accuracy** is given by:\n\n$$\n\\text{Top-N% Accuracy} = \\frac{\\left| \\{\\text{Predicted Top-N% nodes/links}\\} \\cap \\{\\text{True Top-N% nodes/links}\\} \\right|}{|V| \\times (N/100)}\n$$\n\nwhere:\n- $ |V| $ is the total number of nodes/links in the graph.\n- $ N $ is the percentage band (e.g., Top-5%).\n- $ \\cap $ denotes the intersection between the predicted and true Top-N% sets.\n","metadata":{}},{"cell_type":"code","source":"def top_n_accuracy(y_pred, y_true, N=5):\n    num_nodes = len(y_true)\n    top_n = int(num_nodes * (N / 100))\n\n    # Get indices of top N% nodes for predicted and true values\n    top_pred = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n    top_true = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n\n    # Compute accuracy as percentage of overlap\n    accuracy = len(set(top_pred.tolist()) & set(top_true.tolist())) / top_n\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.756488Z","iopub.execute_input":"2025-03-20T09:09:00.756728Z","iopub.status.idle":"2025-03-20T09:09:00.767229Z","shell.execute_reply.started":"2025-03-20T09:09:00.756697Z","shell.execute_reply":"2025-03-20T09:09:00.766609Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"### **Test the framwork**","metadata":{}},{"cell_type":"markdown","source":"### 1000 nodes (power-law-graph-ws)","metadata":{}},{"cell_type":"code","source":"# Step 1: Generate a power-law graph\nG = generate_power_law(n=1000, m=3)\n\n# Step 2: Compute criticality scores\ny_true = compute_criticality_scores(G, compute_weighted_spectrum)\ny_true = torch.tensor(y_true, dtype=torch.float)\n\n# Step 3: Convert to PyG format with node features\ndata = nx_to_pyg(G, y_true)\n\n# Step 4: Define the model\nhidden_dim = 32\nmodel = ILGR(hidden_dim)\nprint(model)\n\n# Step 5: Train the model\ntrain_model(model, data, y_true, epochs=1000, lr=0.001)\n\n# Step 6: Evaluate the model\nmodel.eval()\ny_pred = model(data).detach()  # Ensure no gradients\n\n# Save the trained model\ntorch.save(model.state_dict(), \"trained_model_pl_ws.pth\")\nprint(\"Model saved successfully!\")\n\n# Evaluate the top-N% nodes based on their criticality scores (true values)\ntop_n = int(len(y_true) * 0.05)  # Top 5% nodes\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n\n# Display top-5% criticality scores for both true and predicted values\n# print(\"Top-5% True Criticality Scores:\", y_true[top_n_true_indices].tolist())\n# print(\"Top-5% Predicted Criticality Scores:\", y_pred[top_n_pred_indices].tolist())\n\n\naccuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:09:00.768075Z","iopub.execute_input":"2025-03-20T09:09:00.768361Z","iopub.status.idle":"2025-03-20T09:12:05.249786Z","shell.execute_reply.started":"2025-03-20T09:09:00.768332Z","shell.execute_reply":"2025-03-20T09:12:05.249072Z"}},"outputs":[{"name":"stderr","text":"Computing Criticality Scores: 100%|██████████| 1000/1000 [02:57<00:00,  5.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"ILGR(\n  (embedding): ILGRNodeEmbedding(\n    (conv1): SAGEConv(1, 32, aggr=mean)\n    (conv2): SAGEConv(32, 32, aggr=mean)\n    (conv3): SAGEConv(32, 32, aggr=mean)\n    (attention): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n    )\n  )\n  (regression): RegressionModule(\n    (fc1): Linear(in_features=128, out_features=64, bias=True)\n    (fc2): Linear(in_features=64, out_features=32, bias=True)\n    (fc3): Linear(in_features=32, out_features=1, bias=True)\n  )\n)\n","output_type":"stream"},{"name":"stderr","text":"Training Model: 100%|██████████| 1000/1000 [00:06<00:00, 146.17it/s, loss=0.00438]\n","output_type":"stream"},{"name":"stdout","text":"Model saved successfully!\nTop-5% True Node Indices: [895, 735, 773, 534, 364, 255, 58, 928, 227, 112, 97, 723, 19, 0, 24, 523, 6, 319, 18, 877, 422, 145, 174, 117, 27, 394, 2, 5, 451, 22, 40, 621, 4, 129, 7, 39, 21, 238, 619, 229, 36, 49, 882, 313, 914, 219, 292, 142, 703, 325]\nTop-5% Predicted Node Indices: [895, 735, 773, 534, 364, 255, 58, 928, 227, 112, 97, 723, 19, 0, 24, 523, 319, 6, 18, 877, 422, 145, 174, 117, 27, 394, 2, 5, 451, 22, 40, 621, 4, 129, 7, 39, 21, 238, 619, 229, 36, 49, 882, 313, 914, 219, 292, 703, 142, 325]\nTop-5% Accuracy: 100.00%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"### 1000 nodes (power-law-cluster-graph-ws)","metadata":{}},{"cell_type":"code","source":"# Step 1: Generate a power-law graph cluster\nG = generate_power_law_cluster(n=1000, m=3, p=0.3)\n\n# Step 2: Compute criticality scores\ny_true = compute_criticality_scores(G, compute_weighted_spectrum)\ny_true = torch.tensor(y_true, dtype=torch.float)\n\n# Step 3: Convert to PyG format with node features\ndata = nx_to_pyg(G, y_true)\n\n# Step 4: Define the model\nhidden_dim = 32\nmodel = ILGR(hidden_dim)\nprint(model)\n\n# Step 5: Train the model\ntrain_model(model, data, y_true, epochs=1000, lr=0.001)\n\n# Step 6: Evaluate the model\nmodel.eval()\ny_pred = model(data).detach()  # Ensure no gradients\n\n# Save the trained model\ntorch.save(model.state_dict(), \"trained_model_plc_ws.pth\")\nprint(\"Model saved successfully!\")\n\n\n# Evaluate the top-N% nodes based on their criticality scores (true values)\ntop_n = int(len(y_true) * 0.05)  # Top 5% nodes\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n\n\naccuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:12:05.250580Z","iopub.execute_input":"2025-03-20T09:12:05.250857Z","iopub.status.idle":"2025-03-20T09:15:07.354940Z","shell.execute_reply.started":"2025-03-20T09:12:05.250815Z","shell.execute_reply":"2025-03-20T09:15:07.354196Z"}},"outputs":[{"name":"stderr","text":"Computing Criticality Scores: 100%|██████████| 1000/1000 [02:54<00:00,  5.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"ILGR(\n  (embedding): ILGRNodeEmbedding(\n    (conv1): SAGEConv(1, 32, aggr=mean)\n    (conv2): SAGEConv(32, 32, aggr=mean)\n    (conv3): SAGEConv(32, 32, aggr=mean)\n    (attention): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n    )\n  )\n  (regression): RegressionModule(\n    (fc1): Linear(in_features=128, out_features=64, bias=True)\n    (fc2): Linear(in_features=64, out_features=32, bias=True)\n    (fc3): Linear(in_features=32, out_features=1, bias=True)\n  )\n)\n","output_type":"stream"},{"name":"stderr","text":"Training Model: 100%|██████████| 1000/1000 [00:07<00:00, 139.51it/s, loss=0.000716]\n","output_type":"stream"},{"name":"stdout","text":"Model saved successfully!\nTop-5% True Node Indices: [338, 810, 504, 721, 570, 506, 325, 476, 974, 560, 451, 93, 518, 714, 646, 826, 388, 569, 507, 381, 216, 502, 855, 188, 498, 501, 844, 867, 432, 648, 403, 396, 636, 787, 947, 140, 489, 712, 707, 933, 127, 125, 915, 831, 402, 661, 46, 448, 577, 694]\nTop-5% Predicted Node Indices: [338, 810, 504, 721, 570, 506, 325, 476, 974, 560, 451, 93, 518, 714, 646, 826, 388, 569, 507, 381, 216, 502, 855, 188, 498, 501, 844, 867, 432, 648, 403, 396, 636, 787, 947, 140, 489, 712, 707, 933, 127, 125, 915, 831, 402, 661, 46, 448, 577, 694]\nTop-5% Accuracy: 100.00%\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"### 1000 nodes (power-law-graph-rg)","metadata":{}},{"cell_type":"code","source":"# Step 1: Generate a power-law graph\nG = generate_power_law(n=1000, m=3)\n\n# Step 2: Compute criticality scores\ny_true = compute_criticality_scores(G, compute_effective_resistance)\ny_true = torch.tensor(y_true, dtype=torch.float)\n\n# Step 3: Convert to PyG format with node features\ndata = nx_to_pyg(G, y_true)\n\n# Step 4: Define the model\nhidden_dim = 32\nmodel = ILGR(hidden_dim)\nprint(model)\n\n# Step 5: Train the model\ntrain_model(model, data, y_true, epochs=1000, lr=0.001)\n\n# Step 6: Evaluate the model\nmodel.eval()\ny_pred = model(data).detach()  # Ensure no gradients\n\n# Save the trained model\ntorch.save(model.state_dict(), \"trained_model_pl_rg.pth\")\nprint(\"Model saved successfully!\")\n\n# Evaluate the top-N% nodes based on their criticality scores (true values)\ntop_n = int(len(y_true) * 0.05)  # Top 5% nodes\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n\n\naccuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T10:48:58.190486Z","iopub.execute_input":"2025-03-20T10:48:58.190826Z","iopub.status.idle":"2025-03-20T10:51:57.152034Z","shell.execute_reply.started":"2025-03-20T10:48:58.190800Z","shell.execute_reply":"2025-03-20T10:51:57.151251Z"}},"outputs":[{"name":"stderr","text":"Computing Criticality Scores: 100%|██████████| 1000/1000 [02:51<00:00,  5.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"ILGR(\n  (embedding): ILGRNodeEmbedding(\n    (conv1): SAGEConv(1, 32, aggr=mean)\n    (conv2): SAGEConv(32, 32, aggr=mean)\n    (conv3): SAGEConv(32, 32, aggr=mean)\n    (attention): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n    )\n  )\n  (regression): RegressionModule(\n    (fc1): Linear(in_features=128, out_features=64, bias=True)\n    (fc2): Linear(in_features=64, out_features=32, bias=True)\n    (fc3): Linear(in_features=32, out_features=1, bias=True)\n  )\n)\n","output_type":"stream"},{"name":"stderr","text":"Training Model: 100%|██████████| 1000/1000 [00:07<00:00, 142.26it/s, loss=0.0569]\n","output_type":"stream"},{"name":"stdout","text":"Model saved successfully!\nTop-5% True Node Indices: [171, 136, 116, 928, 371, 497, 21, 41, 401, 423, 615, 541, 901, 321, 684, 892, 339, 537, 133, 832, 547, 690, 682, 211, 999, 466, 592, 599, 800, 877, 504, 289, 965, 784, 956, 938, 193, 108, 748, 186, 636, 242, 262, 831, 574, 650, 775, 620, 332, 818]\nTop-5% Predicted Node Indices: [547, 537, 21, 198, 423, 171, 636, 116, 684, 41, 682, 615, 321, 497, 574, 965, 499, 832, 193, 592, 620, 775, 718, 136, 472, 371, 784, 892, 332, 466, 877, 385, 928, 831, 339, 876, 133, 999, 748, 650, 248, 294, 938, 971, 484, 661, 401, 986, 363, 985]\nTop-5% Accuracy: 72.00%\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"### 1000 nodes (power-law-graph-cluster-rg)","metadata":{}},{"cell_type":"code","source":"# Step 1: Generate a power-law graph\nG = generate_power_law_cluster(n=1000, m=3, p=0.3)\n\n# Step 2: Compute criticality scores\ny_true = compute_criticality_scores(G, compute_effective_resistance)\ny_true = torch.tensor(y_true, dtype=torch.float)\n\n# Step 3: Convert to PyG format with node features\ndata = nx_to_pyg(G, y_true)\n\n# Step 4: Define the model\nhidden_dim = 32\nmodel = ILGR(hidden_dim)\nprint(model)\n\n# Step 5: Train the model\ntrain_model(model, data, y_true, epochs=1000, lr=0.001)\n\n# Step 6: Evaluate the model\nmodel.eval()\ny_pred = model(data).detach()  # Ensure no gradients\n\n# Save the trained model\ntorch.save(model.state_dict(), \"trained_model_plc_rg.pth\")\nprint(\"Model saved successfully!\")\n\n# Evaluate the top-N% nodes based on their criticality scores (true values)\ntop_n = int(len(y_true) * 0.05)  # Top 5% nodes\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n\n\naccuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T10:53:35.862873Z","iopub.execute_input":"2025-03-20T10:53:35.863172Z","iopub.status.idle":"2025-03-20T10:56:32.624289Z","shell.execute_reply.started":"2025-03-20T10:53:35.863152Z","shell.execute_reply":"2025-03-20T10:56:32.623606Z"}},"outputs":[{"name":"stderr","text":"Computing Criticality Scores: 100%|██████████| 1000/1000 [02:49<00:00,  5.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"ILGR(\n  (embedding): ILGRNodeEmbedding(\n    (conv1): SAGEConv(1, 32, aggr=mean)\n    (conv2): SAGEConv(32, 32, aggr=mean)\n    (conv3): SAGEConv(32, 32, aggr=mean)\n    (attention): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n    )\n  )\n  (regression): RegressionModule(\n    (fc1): Linear(in_features=128, out_features=64, bias=True)\n    (fc2): Linear(in_features=64, out_features=32, bias=True)\n    (fc3): Linear(in_features=32, out_features=1, bias=True)\n  )\n)\n","output_type":"stream"},{"name":"stderr","text":"Training Model: 100%|██████████| 1000/1000 [00:06<00:00, 146.58it/s, loss=0.0546]\n","output_type":"stream"},{"name":"stdout","text":"Model saved successfully!\nTop-5% True Node Indices: [856, 623, 594, 862, 923, 845, 661, 203, 453, 949, 307, 351, 613, 430, 224, 255, 102, 461, 719, 890, 609, 390, 790, 746, 848, 865, 767, 358, 912, 356, 625, 439, 197, 513, 370, 839, 341, 728, 838, 154, 737, 293, 500, 858, 310, 262, 624, 467, 592, 730]\nTop-5% Predicted Node Indices: [623, 856, 594, 862, 845, 923, 255, 890, 767, 102, 390, 625, 224, 609, 358, 661, 439, 949, 307, 513, 293, 865, 303, 356, 351, 203, 341, 453, 154, 971, 243, 912, 613, 624, 430, 310, 422, 500, 643, 578, 737, 888, 197, 370, 645, 429, 849, 615, 263, 719]\nTop-5% Accuracy: 76.00%\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"### Bio Yeast Dataset (power_law_ws)","metadata":{}},{"cell_type":"code","source":"# Load the Matrix Market file (Bio Yeast graph)\nfile_path = \"/kaggle/input/bio-yeast/bio-yeast.mtx\"\nmatrix = mmread(file_path)\n\n# Convert to a NetworkX graph\n# Use the appropriate function based on your NetworkX version\ntry:\n    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\nexcept AttributeError:\n    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n\n# Compute criticality scores (assuming your function is defined)\ny_true = compute_criticality_scores(G, compute_weighted_spectrum)\ny_true = torch.tensor(y_true, dtype=torch.float)\n\n# Convert to PyG format\ndata = nx_to_pyg(G, y_true)\n\nprint(f\"Loaded Bio Yeast graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n\n# Define model architecture (must match saved model)\nhidden_dim = 32\nmodel = ILGR(hidden_dim)\n\n# Load trained weights\nmodel.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\", weights_only=True))\nmodel.eval()  # Set to evaluation model\nprint(\"Model loaded successfully!\")\n\n# Make predictions\ny_pred = model(data).detach()\n\n# Evaluate Top-5% Nodes\ntop_n = int(len(y_true) * 0.05)\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist()) \nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n\n# Compute Top-5% Accuracy\naccuracy = top_n_accuracy(y_pred, y_true, N=5)\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:15:07.355755Z","iopub.execute_input":"2025-03-20T09:15:07.355973Z","iopub.status.idle":"2025-03-20T09:26:58.735105Z","shell.execute_reply.started":"2025-03-20T09:15:07.355955Z","shell.execute_reply":"2025-03-20T09:26:58.734187Z"}},"outputs":[{"name":"stderr","text":"Computing Criticality Scores: 100%|██████████| 1458/1458 [11:51<00:00,  2.05it/s]","output_type":"stream"},{"name":"stdout","text":"Loaded Bio Yeast graph with 1458 nodes and 1948 edges.\nModel loaded successfully!\nTop-5% True Node Indices: [542, 1078, 949, 640, 787, 81, 285, 714, 88, 725, 797, 829, 91, 964, 943, 1032, 645, 888, 1, 595, 155, 278, 368, 982, 996, 458, 417, 196, 268, 1027, 1085, 428, 702, 473, 908, 963, 766, 669, 567, 6, 1140, 984, 393, 869, 242, 1043, 937, 560, 406, 398, 63, 2, 850, 30, 1025, 56, 109, 1400, 484, 250, 1114, 890, 1126, 1409, 379, 31, 929, 1115, 517, 251, 201, 1440]\nTop-5% Predicted Node Indices: [1078, 640, 949, 542, 81, 88, 787, 714, 285, 91, 829, 595, 645, 1032, 1, 888, 725, 797, 155, 1027, 368, 964, 196, 428, 458, 996, 1085, 908, 963, 766, 702, 278, 6, 2, 943, 1140, 937, 1043, 560, 268, 982, 398, 406, 379, 31, 1440, 869, 484, 958, 438, 567, 669, 393, 417, 1400, 517, 984, 769, 557, 1126, 421, 1409, 673, 1232, 538, 242, 1115, 164, 30, 687, 1164, 56]\nTop-5% Accuracy: 84.72%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"### Bio Yeast Dataset (power_law_cluster_ws)","metadata":{}},{"cell_type":"code","source":"# Load the Matrix Market file (Bio Yeast graph)\nfile_path = \"/kaggle/input/bio-yeast/bio-yeast.mtx\"\nmatrix = mmread(file_path)\n\n# Convert to a NetworkX graph\n# Use the appropriate function based on your NetworkX version\ntry:\n    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\nexcept AttributeError:\n    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n\n# Compute criticality scores (assuming your function is defined)\ny_true = compute_criticality_scores(G, compute_weighted_spectrum)\ny_true = torch.tensor(y_true, dtype=torch.float)\n\n# Convert to PyG format\ndata = nx_to_pyg(G, y_true)\n\nprint(f\"Loaded Bio Yeast graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n\n# Define model architecture (must match saved model)\nhidden_dim = 32\nmodel = ILGR(hidden_dim)\n\n# Load trained weights\nmodel.load_state_dict(torch.load(\"/kaggle/working/trained_model_plc.pth\", weights_only=True))\nmodel.eval()  # Set to evaluation model\nprint(\"Model loaded successfully!\")\n\n# Make predictions\ny_pred = model(data).detach()\n\n# Evaluate Top-5% Nodes\ntop_n = int(len(y_true) * 0.05)\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist()) \nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n\n# Compute Top-5% Accuracy\naccuracy = top_n_accuracy(y_pred, y_true, N=5)\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:40:36.194304Z","iopub.execute_input":"2025-03-20T09:40:36.194618Z","iopub.status.idle":"2025-03-20T09:52:25.730442Z","shell.execute_reply.started":"2025-03-20T09:40:36.194598Z","shell.execute_reply":"2025-03-20T09:52:25.729501Z"}},"outputs":[{"name":"stderr","text":"Computing Criticality Scores: 100%|██████████| 1458/1458 [11:49<00:00,  2.06it/s]","output_type":"stream"},{"name":"stdout","text":"Loaded Bio Yeast graph with 1458 nodes and 1948 edges.\nModel loaded successfully!\nTop-5% True Node Indices: [542, 1078, 949, 640, 787, 81, 285, 714, 88, 725, 797, 829, 91, 964, 943, 1032, 645, 888, 1, 595, 155, 278, 368, 982, 996, 458, 417, 196, 268, 1027, 1085, 428, 702, 473, 908, 963, 766, 669, 567, 6, 1140, 984, 393, 869, 242, 1043, 937, 560, 406, 398, 63, 2, 850, 30, 1025, 56, 109, 1400, 484, 250, 1114, 890, 1126, 1409, 379, 31, 929, 1115, 517, 251, 201, 1440]\nTop-5% Predicted Node Indices: [1078, 640, 70, 81, 949, 542, 88, 787, 725, 797, 943, 285, 714, 964, 888, 278, 155, 645, 91, 829, 595, 908, 1, 982, 1032, 1085, 368, 996, 702, 268, 458, 1027, 196, 428, 417, 963, 766, 1140, 6, 567, 473, 669, 869, 393, 242, 984, 1043, 560, 937, 398, 406, 63, 2, 30, 1403, 1400, 484, 1126, 56, 109, 1409, 1114, 687, 890, 1115, 31, 379, 1387, 1402, 929, 517, 421]\nTop-5% Accuracy: 91.67%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"### US Power Grid Dataset","metadata":{}},{"cell_type":"code","source":"\"\"\"# Load the Matrix Market file (US Power Grid graph)\nfile_path = \"/kaggle/input/power-us-grid/power-US-Grid.mtx\"\nmatrix = mmread(file_path)\n\n# Convert to a NetworkX graph\n# Use the appropriate function based on your NetworkX version\ntry:\n    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\nexcept AttributeError:\n    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n\n# Compute criticality scores (assuming your function is defined)\ny_true = compute_criticality_scores(G, compute_effective_resistance)\ny_true = torch.tensor(y_true, dtype=torch.float)\n\n# Convert to PyG format\ndata = nx_to_pyg(G, y_true)\n\nprint(f\"Loaded US Power Grid graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n\n# Define model architecture (must match saved model)\nhidden_dim = 32\nmodel = ILGR(hidden_dim)\n\n# Load trained weights\nmodel.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\"))\nmodel.eval()  # Set to evaluation model\nprint(\"Model loaded successfully!\")\n\n# Make predictions\ny_pred = model(data).detach()\n\n# Evaluate Top-5% Nodes\ntop_n = int(len(y_true) * 0.05)\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n\n# Compute Top-5% Accuracy\naccuracy = top_n_accuracy(y_pred, y_true, N=5)\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:26:58.735924Z","iopub.execute_input":"2025-03-20T09:26:58.736171Z","iopub.status.idle":"2025-03-20T09:26:58.742363Z","shell.execute_reply.started":"2025-03-20T09:26:58.736150Z","shell.execute_reply":"2025-03-20T09:26:58.741410Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'# Load the Matrix Market file (US Power Grid graph)\\nfile_path = \"/kaggle/input/power-us-grid/power-US-Grid.mtx\"\\nmatrix = mmread(file_path)\\n\\n# Convert to a NetworkX graph\\n# Use the appropriate function based on your NetworkX version\\ntry:\\n    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\\nexcept AttributeError:\\n    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\\n\\n# Compute criticality scores (assuming your function is defined)\\ny_true = compute_criticality_scores(G, compute_effective_resistance)\\ny_true = torch.tensor(y_true, dtype=torch.float)\\n\\n# Convert to PyG format\\ndata = nx_to_pyg(G, y_true)\\n\\nprint(f\"Loaded US Power Grid graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\\n\\n# Define model architecture (must match saved model)\\nhidden_dim = 32\\nmodel = ILGR(hidden_dim)\\n\\n# Load trained weights\\nmodel.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\"))\\nmodel.eval()  # Set to evaluation model\\nprint(\"Model loaded successfully!\")\\n\\n# Make predictions\\ny_pred = model(data).detach()\\n\\n# Evaluate Top-5% Nodes\\ntop_n = int(len(y_true) * 0.05)\\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\\n\\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\\nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\\n\\n# Compute Top-5% Accuracy\\naccuracy = top_n_accuracy(y_pred, y_true, N=5)\\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")'"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}