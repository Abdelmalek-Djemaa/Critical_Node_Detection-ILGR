{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37ae539",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:40.898480Z",
     "iopub.status.busy": "2025-03-20T09:29:40.898184Z",
     "iopub.status.idle": "2025-03-20T09:29:46.450851Z",
     "shell.execute_reply": "2025-03-20T09:29:46.449745Z"
    },
    "papermill": {
     "duration": 5.561762,
     "end_time": "2025-03-20T09:29:46.452667",
     "exception": false,
     "start_time": "2025-03-20T09:29:40.890905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee13a908",
   "metadata": {
    "papermill": {
     "duration": 0.005652,
     "end_time": "2025-03-20T09:29:46.464925",
     "exception": false,
     "start_time": "2025-03-20T09:29:46.459273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7713e70e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:46.477330Z",
     "iopub.status.busy": "2025-03-20T09:29:46.477094Z",
     "iopub.status.idle": "2025-03-20T09:29:56.332604Z",
     "shell.execute_reply": "2025-03-20T09:29:56.331676Z"
    },
    "papermill": {
     "duration": 9.863513,
     "end_time": "2025-03-20T09:29:56.334232",
     "exception": false,
     "start_time": "2025-03-20T09:29:46.470719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de4832",
   "metadata": {
    "papermill": {
     "duration": 0.006245,
     "end_time": "2025-03-20T09:29:56.350404",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.344159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Graph Robustness Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ddb228",
   "metadata": {
    "papermill": {
     "duration": 0.005646,
     "end_time": "2025-03-20T09:29:56.361971",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.356325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. Effective Graph Resistance (EGR)**  \n",
    "   $$\n",
    "   R_g = \\frac{2}{N-1} \\sum_{i=1}^{N-c} \\frac{1}{\\lambda_i}\n",
    "   $$\n",
    "   where $ \\lambda_i $ are the eigenvalues of the Laplacian matrix of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52759368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.374761Z",
     "iopub.status.busy": "2025-03-20T09:29:56.374281Z",
     "iopub.status.idle": "2025-03-20T09:29:56.378267Z",
     "shell.execute_reply": "2025-03-20T09:29:56.377655Z"
    },
    "papermill": {
     "duration": 0.011638,
     "end_time": "2025-03-20T09:29:56.379424",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.367786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_effective_resistance(graph):\n",
    "    laplacian = nx.laplacian_matrix(graph).toarray()\n",
    "    eigenvalues = np.linalg.eigvalsh(laplacian)\n",
    "    eigenvalues = eigenvalues[eigenvalues > 1e-8]  # Avoid zero eigenvalues\n",
    "    N = graph.number_of_nodes()\n",
    "    return (2 / (N - 1)) * np.sum(1 / eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43049394",
   "metadata": {
    "papermill": {
     "duration": 0.005701,
     "end_time": "2025-03-20T09:29:56.391114",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.385413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2. Weighted Spectrum (WS)**  \n",
    "   $$\n",
    "   W_s = \\sum_i (1 - \\lambda_i)^n\n",
    "   $$\n",
    "   where $ n $ controls the depth of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd67ee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.403466Z",
     "iopub.status.busy": "2025-03-20T09:29:56.403252Z",
     "iopub.status.idle": "2025-03-20T09:29:56.406415Z",
     "shell.execute_reply": "2025-03-20T09:29:56.405839Z"
    },
    "papermill": {
     "duration": 0.010803,
     "end_time": "2025-03-20T09:29:56.407755",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.396952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weighted_spectrum(graph, n=3):\n",
    "    laplacian = nx.normalized_laplacian_matrix(graph).toarray()\n",
    "    eigenvalues = np.linalg.eigvalsh(laplacian)\n",
    "    return np.sum((1 - eigenvalues) ** n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd77cf86",
   "metadata": {
    "papermill": {
     "duration": 0.005581,
     "end_time": "2025-03-20T09:29:56.419174",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.413593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Algorithm 1: ILGR Embedding Module\n",
    "**Input:** Graph $ G $, input node features $ X_v $ $ \\forall v \\in V $, unknown model weights $ W $ (combination weights) and $ Q $ (aggregation weights).\n",
    "\n",
    "**Output:** Nodes embedding vector $ z_v $ $ \\forall v \\in V $.\n",
    "\n",
    "**1. Initialize**: $ h^0_v = X_v $ for all $ v \\in V $.\n",
    "**2. For each layer** $ l = 1 $ to $ L $ do:\n",
    "   - For each node $ v = 1 $ to $ V $:\n",
    "     1. Compute neighborhood embedding using attention mechanism:\n",
    "        $$\n",
    "        h^l_{N(v)} = \\text{Attention}(Q^l h^{l-1}_k) \\quad \\forall k \\in N(v)\n",
    "        $$\n",
    "     2. Compute new embedding for node $ v $ using a **skip connection**:\n",
    "        $$\n",
    "        h^l_v = \\text{ReLU} \\left( W^l \\left[ h^{l-1}_v || h^{l-2}_v || h^l_{N(v)} \\right] \\right)\n",
    "        $$\n",
    "**3. Return**: Final embedding vector $ z_v = h^L_v $ for all $ v \\in V $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39badc54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.431464Z",
     "iopub.status.busy": "2025-03-20T09:29:56.431262Z",
     "iopub.status.idle": "2025-03-20T09:29:56.435801Z",
     "shell.execute_reply": "2025-03-20T09:29:56.435212Z"
    },
    "papermill": {
     "duration": 0.011936,
     "end_time": "2025-03-20T09:29:56.436903",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.424967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ILGRNodeEmbedding(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(1, hidden_channels)  # input feature: criticality \n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.attention = torch.nn.MultiheadAttention(hidden_channels, 1)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # Skip connections and attention\n",
    "        h1 = torch.relu(self.conv1(x, edge_index))\n",
    "        h2 = torch.relu(self.conv2(h1, edge_index))\n",
    "        h3 = torch.relu(self.conv3(h2, edge_index))\n",
    "        h, _ = self.attention(h3, h3, h3)\n",
    "        return torch.cat([h1, h2, h3, h], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d242d166",
   "metadata": {
    "papermill": {
     "duration": 0.005597,
     "end_time": "2025-03-20T09:29:56.448443",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.442846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Regression Module\n",
    "\n",
    "The regression module applies a **non-linear transformation** using multiple layers:\n",
    "\n",
    "$$\n",
    "y_m = f(W_m \\cdot y_{m-1} + b_m)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ y_m $ is the output of the $ m^{th} $ layer.\n",
    "- $ W_m $ and $ b_m $ are the **weights** and **biases** of the $ m^{th} $ layer.\n",
    "- $ f $ is an **activation function**\n",
    "- The input to the first layer is the **node embedding**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c87bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.460988Z",
     "iopub.status.busy": "2025-03-20T09:29:56.460775Z",
     "iopub.status.idle": "2025-03-20T09:29:56.464729Z",
     "shell.execute_reply": "2025-03-20T09:29:56.464108Z"
    },
    "papermill": {
     "duration": 0.011461,
     "end_time": "2025-03-20T09:29:56.465845",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.454384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegressionModule(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16073e92",
   "metadata": {
    "papermill": {
     "duration": 0.005448,
     "end_time": "2025-03-20T09:29:56.477174",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.471726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a250e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.489117Z",
     "iopub.status.busy": "2025-03-20T09:29:56.488910Z",
     "iopub.status.idle": "2025-03-20T09:29:56.492652Z",
     "shell.execute_reply": "2025-03-20T09:29:56.492055Z"
    },
    "papermill": {
     "duration": 0.010848,
     "end_time": "2025-03-20T09:29:56.493718",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.482870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ILGR(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.embedding = ILGRNodeEmbedding(hidden_channels)\n",
    "        self.regression = RegressionModule(hidden_channels * 4)  # Concatenated embeddings\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        embedding = self.embedding(x, edge_index)\n",
    "        return self.regression(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e8bc1",
   "metadata": {
    "papermill": {
     "duration": 0.005533,
     "end_time": "2025-03-20T09:29:56.505212",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.499679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Criticality Score Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdbbee1",
   "metadata": {
    "papermill": {
     "duration": 0.005523,
     "end_time": "2025-03-20T09:29:56.516467",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.510944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Algorithm 3: Conventional Approach for Identifying Critical Nodes/Links\n",
    "**Input:** Graph $ G $ with $ V $ nodes.\n",
    "**Output:** Node critical scores.\n",
    "\n",
    "**1. For each node/link** $ n $ in $ V $:\n",
    "   - Remove node $ n $ from the graph $ G $.\n",
    "   - Compute robustness metric of the **residual graph** $ (G - n) $.\n",
    "   - Assign a **criticality score** to node $ n $.\n",
    "\n",
    "**2. End loop**.\n",
    "\n",
    "3. Rank nodes based on computed **criticality scores**.\n",
    "4. Top ranks correspond to the **most critical nodes**.\n",
    "**5. Return**: Top $ N\\% $ of most critical nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70fe88b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.528654Z",
     "iopub.status.busy": "2025-03-20T09:29:56.528418Z",
     "iopub.status.idle": "2025-03-20T09:29:56.531926Z",
     "shell.execute_reply": "2025-03-20T09:29:56.531311Z"
    },
    "papermill": {
     "duration": 0.010827,
     "end_time": "2025-03-20T09:29:56.533106",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.522279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_criticality_scores(graph, metric):\n",
    "    scores = []\n",
    "    for node in tqdm(graph.nodes(), desc=\"Computing Criticality Scores\"):\n",
    "        subgraph = graph.copy()\n",
    "        subgraph.remove_node(node)\n",
    "        score = metric(graph) - metric(subgraph)  # Drop in robustness\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa719c3",
   "metadata": {
    "papermill": {
     "duration": 0.005543,
     "end_time": "2025-03-20T09:29:56.544429",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.538886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ranking Loss\n",
    "$$\n",
    "     L_{ij} = -f(r_{ij}) \\log(σ(\\hat{y}_{ij})) - (1 - f(r_{ij})) \\log(1 - σ(\\hat{y}_{ij}))\n",
    "     $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be992c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.556913Z",
     "iopub.status.busy": "2025-03-20T09:29:56.556715Z",
     "iopub.status.idle": "2025-03-20T09:29:56.561474Z",
     "shell.execute_reply": "2025-03-20T09:29:56.560876Z"
    },
    "papermill": {
     "duration": 0.012384,
     "end_time": "2025-03-20T09:29:56.562732",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.550348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def pairwise_ranking_loss(y_pred, y_true):\\n    # Compute all pairwise differences\\n    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # r_ij = r_i - r_j\\n    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # y_ij = y_i - y_j\\n\\n    # Apply sigmoid function to ground truth ranking differences f(r_ij)\\n    f_rij = torch.sigmoid(diff_true)\\n\\n    # Compute sigmoid of predicted ranking differences σ(ŷ_ij)\\n    sigma_y_pred = torch.sigmoid(diff_pred)\\n\\n    # Compute the pairwise ranking loss\\n    loss = -f_rij * torch.log(sigma_y_pred + 1e-10) - (1 - f_rij) * torch.log(1 - sigma_y_pred + 1e-10)\\n\\n    # Mask to consider only valid pairs (i < j) to avoid redundant comparisons\\n    mask = torch.triu(torch.ones_like(loss), diagonal=1).bool()\\n    loss = loss[mask]\\n\\n    # Compute mean loss over valid pairs\\n    return loss.mean()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def pairwise_ranking_loss(y_pred, y_true):\n",
    "    # Compute all pairwise differences\n",
    "    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # r_ij = r_i - r_j\n",
    "    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # y_ij = y_i - y_j\n",
    "\n",
    "    # Apply sigmoid function to ground truth ranking differences f(r_ij)\n",
    "    f_rij = torch.sigmoid(diff_true)\n",
    "\n",
    "    # Compute sigmoid of predicted ranking differences σ(ŷ_ij)\n",
    "    sigma_y_pred = torch.sigmoid(diff_pred)\n",
    "\n",
    "    # Compute the pairwise ranking loss\n",
    "    loss = -f_rij * torch.log(sigma_y_pred + 1e-10) - (1 - f_rij) * torch.log(1 - sigma_y_pred + 1e-10)\n",
    "\n",
    "    # Mask to consider only valid pairs (i < j) to avoid redundant comparisons\n",
    "    mask = torch.triu(torch.ones_like(loss), diagonal=1).bool()\n",
    "    loss = loss[mask]\n",
    "\n",
    "    # Compute mean loss over valid pairs\n",
    "    return loss.mean()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cbca0a",
   "metadata": {
    "papermill": {
     "duration": 0.005637,
     "end_time": "2025-03-20T09:29:56.574250",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.568613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Optimize Pairwise Loss Computation\n",
    "Replace the nested-loop pairwise loss with a vectorized implementation to handle large graphs (other version of pairwise ranking loss) :\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N(N-1)/2} \\sum_{i < j} \\log \\left( 1 + \\exp \\left( - \\text{sign}(y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)}) \\cdot (y_{\\text{pred}}^{(i)} - y_{\\text{pred}}^{(j)}) \\right) \\right)\n",
    "$$\n",
    "\n",
    "### Where:\n",
    "- $ y_{\\text{pred}}^{(i)} $ and $ y_{\\text{pred}}^{(j)} $ are the predicted values for the $i$-th and $j$-th items, respectively.\n",
    "- $ y_{\\text{true}}^{(i)} $ and $ y_{\\text{true}}^{(j)} $ are the true labels for the $i$-th and $j$-th items, respectively.\n",
    "- $ \\text{sign}(x) $ is the sign function:\n",
    "- $ \\text{sign}(x) = +1 $ if $ x > 0 $\n",
    "- $ \\text{sign}(x) = -1 $ if $ x < 0 $\n",
    "\n",
    "### Breakdown:\n",
    "\n",
    "- $ y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)} $: The difference in the true values (target ranking).\n",
    "- $ y_{\\text{pred}}^{(i)} - y_{\\text{pred}}^{(j)} $: The difference in the predicted values (model's ranking).\n",
    "- $ \\text{sign}(y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)}) $ ensures that:\n",
    "- If the true ranking is correct (i.e., $ y_{\\text{true}}^{(i)} > y_{\\text{true}}^{(j)} $), we want $ y_{\\text{pred}}^{(i)} $ to be greater than $ y_{\\text{pred}}^{(j)} $.\n",
    "- The difference in predictions should match the expected order.\n",
    "\n",
    "This formulation helps enforce the correct ranking order between pairs, which is critical in learning-to-rank tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85fa51cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.586530Z",
     "iopub.status.busy": "2025-03-20T09:29:56.586335Z",
     "iopub.status.idle": "2025-03-20T09:29:56.590372Z",
     "shell.execute_reply": "2025-03-20T09:29:56.589614Z"
    },
    "papermill": {
     "duration": 0.011339,
     "end_time": "2025-03-20T09:29:56.591467",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.580128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_ranking_loss(y_pred, y_true):\n",
    "    y_pred = y_pred.squeeze()\n",
    "    y_true = y_true.squeeze()\n",
    "    \n",
    "    # Compute all pairwise differences\n",
    "    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # Shape [N, N]\n",
    "    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # Shape [N, N]\n",
    "    \n",
    "    # Mask for valid pairs (i < j)\n",
    "    mask = torch.triu(torch.ones_like(diff_true), diagonal=1).bool()\n",
    "    diff_pred = diff_pred[mask]\n",
    "    diff_true = diff_true[mask]\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = torch.log(1 + torch.exp(-torch.sign(diff_true) * diff_pred)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55c9dd7",
   "metadata": {
    "papermill": {
     "duration": 0.005649,
     "end_time": "2025-03-20T09:29:56.603077",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.597428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Graph Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8372bb",
   "metadata": {
    "papermill": {
     "duration": 0.005637,
     "end_time": "2025-03-20T09:29:56.614575",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.608938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate Synthetic Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "794d3731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.626955Z",
     "iopub.status.busy": "2025-03-20T09:29:56.626756Z",
     "iopub.status.idle": "2025-03-20T09:29:56.629847Z",
     "shell.execute_reply": "2025-03-20T09:29:56.629272Z"
    },
    "papermill": {
     "duration": 0.010624,
     "end_time": "2025-03-20T09:29:56.631061",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.620437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Power-law graph (Barabási-Albert model)\n",
    "def generate_power_law(n, m):\n",
    "    return nx.barabasi_albert_graph(n, m)\n",
    "\n",
    "# Power-law cluster graph (Holme-Kim model)\n",
    "def generate_power_law_cluster(n, m, p):\n",
    "    return nx.powerlaw_cluster_graph(n, m, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0bc69a",
   "metadata": {
    "papermill": {
     "duration": 0.005601,
     "end_time": "2025-03-20T09:29:56.642510",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.636909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### real-world datasets (load function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58902d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.655584Z",
     "iopub.status.busy": "2025-03-20T09:29:56.655355Z",
     "iopub.status.idle": "2025-03-20T09:29:56.658376Z",
     "shell.execute_reply": "2025-03-20T09:29:56.657788Z"
    },
    "papermill": {
     "duration": 0.010592,
     "end_time": "2025-03-20T09:29:56.659526",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.648934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_real_world_graph(dataset_name):\n",
    "    G = nx.read_edgelist(dataset_name, nodetype=int)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08211813",
   "metadata": {
    "papermill": {
     "duration": 0.00598,
     "end_time": "2025-03-20T09:29:56.671422",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.665442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert NetworkX graph to PyTorch Geometric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7457e2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.683863Z",
     "iopub.status.busy": "2025-03-20T09:29:56.683662Z",
     "iopub.status.idle": "2025-03-20T09:29:56.686911Z",
     "shell.execute_reply": "2025-03-20T09:29:56.686217Z"
    },
    "papermill": {
     "duration": 0.010937,
     "end_time": "2025-03-20T09:29:56.688156",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.677219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nx_to_pyg(nx_graph, criticality_scores):\n",
    "    # Convert NetworkX graph to PyG format\n",
    "    pyg_data = from_networkx(nx_graph)\n",
    "\n",
    "    # Use criticality scores as node features\n",
    "    pyg_data.x = criticality_scores.view(-1, 1)\n",
    "\n",
    "    return pyg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df4a91",
   "metadata": {
    "papermill": {
     "duration": 0.005665,
     "end_time": "2025-03-20T09:29:56.699763",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.694098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Algorithm 2: ILGR Training\n",
    "**Input:** Model with unknown weights.\n",
    "**Output:** Trained model.\n",
    "\n",
    "1. Compute ground truth **criticality scores** of nodes based on graph robustness score.\n",
    "2. **For each epoch do**:\n",
    "   - Get each **node embedding** from the embedding module.\n",
    "   - Estimate **criticality scores** of nodes/links using the regression module.\n",
    "   - Update weights of both modules by solving the loss function:\n",
    "     $$\n",
    "     L_{ij} = -f(r_{ij}) \\log(σ(\\hat{y}_{ij})) - (1 - f(r_{ij})) \\log(1 - σ(\\hat{y}_{ij}))\n",
    "     $$\n",
    "3. **End loop**.\n",
    "4. Predict nodescores on the test graph.\n",
    "5. **Return**: Top $ N\\% $ of most critical nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91247ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.712425Z",
     "iopub.status.busy": "2025-03-20T09:29:56.712230Z",
     "iopub.status.idle": "2025-03-20T09:29:56.716784Z",
     "shell.execute_reply": "2025-03-20T09:29:56.716148Z"
    },
    "papermill": {
     "duration": 0.012211,
     "end_time": "2025-03-20T09:29:56.717882",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.705671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, data, y_true, epochs=100, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    data, y_true = data.to(device), y_true.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    progress_bar = tqdm(range(epochs), desc=\"Training Model\", dynamic_ncols=True)\n",
    "    \n",
    "    for epoch in progress_bar:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(data)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = pairwise_ranking_loss(y_pred, y_true)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar with loss value\n",
    "        progress_bar.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ccf8a",
   "metadata": {
    "papermill": {
     "duration": 0.005594,
     "end_time": "2025-03-20T09:29:56.729454",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.723860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Evaluation Metrics: Top-N% Accuracy**\n",
    "\n",
    "To measure the accuracy of our framework, we use **Top-N% Accuracy**, which is defined as the percentage of overlap between the predicted Top-N% nodes/links and the ground-truth Top-N% nodes/links (computed using a conventional baseline approach). \n",
    "\n",
    "The formula for **Top-N% Accuracy** is given by:\n",
    "\n",
    "$$\n",
    "\\text{Top-N% Accuracy} = \\frac{\\left| \\{\\text{Predicted Top-N% nodes/links}\\} \\cap \\{\\text{True Top-N% nodes/links}\\} \\right|}{|V| \\times (N/100)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ |V| $ is the total number of nodes/links in the graph.\n",
    "- $ N $ is the percentage band (e.g., Top-5%).\n",
    "- $ \\cap $ denotes the intersection between the predicted and true Top-N% sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bea5b65a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.741872Z",
     "iopub.status.busy": "2025-03-20T09:29:56.741670Z",
     "iopub.status.idle": "2025-03-20T09:29:56.745427Z",
     "shell.execute_reply": "2025-03-20T09:29:56.744836Z"
    },
    "papermill": {
     "duration": 0.011379,
     "end_time": "2025-03-20T09:29:56.746668",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.735289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_n_accuracy(y_pred, y_true, N=5):\n",
    "    num_nodes = len(y_true)\n",
    "    top_n = int(num_nodes * (N / 100))\n",
    "\n",
    "    # Get indices of top N% nodes for predicted and true values\n",
    "    top_pred = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "    top_true = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "    # Compute accuracy as percentage of overlap\n",
    "    accuracy = len(set(top_pred.tolist()) & set(top_true.tolist())) / top_n\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ed1a3",
   "metadata": {
    "papermill": {
     "duration": 0.005659,
     "end_time": "2025-03-20T09:29:56.758154",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.752495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Test the framwork**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641975d",
   "metadata": {
    "papermill": {
     "duration": 0.005655,
     "end_time": "2025-03-20T09:29:56.769607",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.763952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1000 nodes (power-law graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83c50fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:29:56.781917Z",
     "iopub.status.busy": "2025-03-20T09:29:56.781705Z",
     "iopub.status.idle": "2025-03-20T09:33:28.081971Z",
     "shell.execute_reply": "2025-03-20T09:33:28.081167Z"
    },
    "papermill": {
     "duration": 211.307888,
     "end_time": "2025-03-20T09:33:28.083292",
     "exception": false,
     "start_time": "2025-03-20T09:29:56.775404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1000/1000 [03:22<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILGR(\n",
      "  (embedding): ILGRNodeEmbedding(\n",
      "    (conv1): SAGEConv(1, 32, aggr=mean)\n",
      "    (conv2): SAGEConv(32, 32, aggr=mean)\n",
      "    (conv3): SAGEConv(32, 32, aggr=mean)\n",
      "    (attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (regression): RegressionModule(\n",
      "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 1000/1000 [00:07<00:00, 127.02it/s, loss=0.00512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Top-5% True Node Indices: [735, 359, 357, 680, 423, 562, 484, 312, 141, 503, 42, 50, 273, 570, 674, 242, 787, 10, 750, 85, 65, 20, 757, 842, 101, 335, 511, 202, 1, 22, 0, 388, 377, 880, 17, 14, 24, 3, 318, 634, 210, 897, 147, 197, 849, 689, 15, 853, 38, 907]\n",
      "Top-5% Predicted Node Indices: [359, 735, 357, 680, 423, 562, 484, 312, 141, 503, 42, 50, 273, 570, 674, 242, 787, 10, 750, 85, 65, 20, 757, 842, 101, 335, 511, 202, 1, 22, 0, 388, 377, 880, 17, 14, 24, 3, 318, 634, 210, 897, 147, 197, 849, 689, 15, 853, 38, 907]\n",
      "Top-5% Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate a power-law graph\n",
    "G = generate_power_law(n=1000, m=3)\n",
    "\n",
    "# Step 2: Compute criticality scores\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Step 3: Convert to PyG format with node features\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "# Step 4: Define the model\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "print(model)\n",
    "\n",
    "# Step 5: Train the model\n",
    "train_model(model, data, y_true, epochs=1000, lr=0.001)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(data).detach()  # Ensure no gradients\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model_pl.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Evaluate the top-N% nodes based on their criticality scores (true values)\n",
    "top_n = int(len(y_true) * 0.05)  # Top 5% nodes\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Display top-5% criticality scores for both true and predicted values\n",
    "# print(\"Top-5% True Criticality Scores:\", y_true[top_n_true_indices].tolist())\n",
    "# print(\"Top-5% Predicted Criticality Scores:\", y_pred[top_n_pred_indices].tolist())\n",
    "\n",
    "\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203b45e",
   "metadata": {
    "papermill": {
     "duration": 0.092261,
     "end_time": "2025-03-20T09:33:28.310442",
     "exception": false,
     "start_time": "2025-03-20T09:33:28.218181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1000 nodes (power-law cluster graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8a76eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:33:28.497725Z",
     "iopub.status.busy": "2025-03-20T09:33:28.497405Z",
     "iopub.status.idle": "2025-03-20T09:36:59.347151Z",
     "shell.execute_reply": "2025-03-20T09:36:59.346226Z"
    },
    "papermill": {
     "duration": 210.945244,
     "end_time": "2025-03-20T09:36:59.348480",
     "exception": false,
     "start_time": "2025-03-20T09:33:28.403236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1000/1000 [03:23<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILGR(\n",
      "  (embedding): ILGRNodeEmbedding(\n",
      "    (conv1): SAGEConv(1, 32, aggr=mean)\n",
      "    (conv2): SAGEConv(32, 32, aggr=mean)\n",
      "    (conv3): SAGEConv(32, 32, aggr=mean)\n",
      "    (attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (regression): RegressionModule(\n",
      "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 1000/1000 [00:06<00:00, 144.80it/s, loss=0.000819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Top-5% True Node Indices: [476, 514, 384, 601, 217, 953, 894, 785, 763, 767, 696, 176, 468, 203, 248, 987, 586, 191, 300, 919, 197, 169, 760, 321, 957, 751, 362, 541, 558, 828, 163, 962, 952, 603, 864, 610, 644, 212, 385, 752, 255, 128, 161, 907, 281, 635, 272, 617, 82, 417]\n",
      "Top-5% Predicted Node Indices: [514, 476, 384, 601, 217, 953, 894, 785, 763, 767, 696, 176, 468, 203, 248, 987, 586, 191, 300, 919, 197, 169, 760, 321, 957, 751, 541, 362, 558, 828, 163, 962, 952, 603, 864, 610, 644, 212, 385, 752, 255, 128, 161, 907, 281, 635, 272, 617, 82, 417]\n",
      "Top-5% Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate a power-law graph cluster\n",
    "G = generate_power_law_cluster(n=1000, m=3, p=0.3)\n",
    "\n",
    "# Step 2: Compute criticality scores\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Step 3: Convert to PyG format with node features\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "# Step 4: Define the model\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "print(model)\n",
    "\n",
    "# Step 5: Train the model\n",
    "train_model(model, data, y_true, epochs=1000, lr=0.001)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(data).detach()  # Ensure no gradients\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model_plc.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "\n",
    "# Evaluate the top-N% nodes based on their criticality scores (true values)\n",
    "top_n = int(len(y_true) * 0.05)  # Top 5% nodes\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Display top-5% criticality scores for both true and predicted values\n",
    "# print(\"Top-5% True Criticality Scores:\", y_true[top_n_true_indices].tolist())\n",
    "# print(\"Top-5% Predicted Criticality Scores:\", y_pred[top_n_pred_indices].tolist())\n",
    "\n",
    "\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d28f39",
   "metadata": {
    "papermill": {
     "duration": 0.182155,
     "end_time": "2025-03-20T09:36:59.719044",
     "exception": false,
     "start_time": "2025-03-20T09:36:59.536889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bio Yeast Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8f65aea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:37:00.085816Z",
     "iopub.status.busy": "2025-03-20T09:37:00.085510Z",
     "iopub.status.idle": "2025-03-20T09:48:43.553541Z",
     "shell.execute_reply": "2025-03-20T09:48:43.552798Z"
    },
    "papermill": {
     "duration": 703.654627,
     "end_time": "2025-03-20T09:48:43.555825",
     "exception": false,
     "start_time": "2025-03-20T09:36:59.901198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1458/1458 [11:43<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Bio Yeast graph with 1458 nodes and 1948 edges.\n",
      "Model loaded successfully!\n",
      "Top-5% True Node Indices: [542, 1078, 949, 640, 787, 81, 285, 714, 88, 725, 797, 829, 91, 964, 943, 1032, 645, 888, 1, 595, 155, 278, 368, 982, 996, 458, 417, 196, 268, 1027, 1085, 428, 702, 473, 908, 963, 766, 669, 567, 6, 1140, 984, 393, 869, 242, 1043, 937, 560, 406, 398, 63, 2, 850, 30, 1025, 56, 109, 1400, 484, 250, 1114, 890, 1126, 1409, 379, 31, 929, 1115, 517, 251, 201, 1440]\n",
      "Top-5% Predicted Node Indices: [1078, 640, 714, 285, 88, 949, 542, 787, 81, 829, 91, 797, 725, 595, 1032, 964, 943, 155, 645, 888, 1, 1027, 278, 1085, 982, 428, 196, 368, 908, 702, 458, 996, 268, 963, 766, 417, 1140, 6, 1043, 937, 560, 567, 2, 869, 242, 70, 398, 406, 393, 669, 984, 484, 379, 31, 1400, 30, 1440, 517, 438, 958, 1409, 1126, 56, 109, 1114, 1115, 421, 473, 769, 929, 557, 890]\n",
      "Top-5% Accuracy: 91.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Matrix Market file (Bio Yeast graph)\n",
    "file_path = \"/kaggle/input/bio-yeast/bio-yeast.mtx\"\n",
    "matrix = mmread(file_path)\n",
    "\n",
    "# Convert to a NetworkX graph\n",
    "# Use the appropriate function based on your NetworkX version\n",
    "try:\n",
    "    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\n",
    "except AttributeError:\n",
    "    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n",
    "\n",
    "# Compute criticality scores (assuming your function is defined)\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Convert to PyG format\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "print(f\"Loaded Bio Yeast graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "# Define model architecture (must match saved model)\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\", weights_only=True))\n",
    "model.eval()  # Set to evaluation model\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model(data).detach()\n",
    "\n",
    "# Evaluate Top-5% Nodes\n",
    "top_n = int(len(y_true) * 0.05)\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist()) \n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Compute Top-5% Accuracy\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72711c3",
   "metadata": {
    "papermill": {
     "duration": 0.247931,
     "end_time": "2025-03-20T09:48:44.057264",
     "exception": false,
     "start_time": "2025-03-20T09:48:43.809333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### US Power Grid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d38df3d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T09:48:44.625630Z",
     "iopub.status.busy": "2025-03-20T09:48:44.625276Z",
     "iopub.status.idle": "2025-03-20T09:48:44.630458Z",
     "shell.execute_reply": "2025-03-20T09:48:44.629641Z"
    },
    "papermill": {
     "duration": 0.315216,
     "end_time": "2025-03-20T09:48:44.631867",
     "exception": false,
     "start_time": "2025-03-20T09:48:44.316651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load the Matrix Market file (US Power Grid graph)\\nfile_path = \"/kaggle/input/power-us-grid/power-US-Grid.mtx\"\\nmatrix = mmread(file_path)\\n\\n# Convert to a NetworkX graph\\n# Use the appropriate function based on your NetworkX version\\ntry:\\n    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\\nexcept AttributeError:\\n    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\\n\\n# Compute criticality scores (assuming your function is defined)\\ny_true = compute_criticality_scores(G, compute_effective_resistance)\\ny_true = torch.tensor(y_true, dtype=torch.float)\\n\\n# Convert to PyG format\\ndata = nx_to_pyg(G, y_true)\\n\\nprint(f\"Loaded US Power Grid graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\\n\\n# Define model architecture (must match saved model)\\nhidden_dim = 32\\nmodel = ILGR(hidden_dim)\\n\\n# Load trained weights\\nmodel.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\"))\\nmodel.eval()  # Set to evaluation model\\nprint(\"Model loaded successfully!\")\\n\\n# Make predictions\\ny_pred = model(data).detach()\\n\\n# Evaluate Top-5% Nodes\\ntop_n = int(len(y_true) * 0.05)\\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\\n\\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\\nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\\n\\n# Compute Top-5% Accuracy\\naccuracy = top_n_accuracy(y_pred, y_true, N=5)\\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Load the Matrix Market file (US Power Grid graph)\n",
    "file_path = \"/kaggle/input/power-us-grid/power-US-Grid.mtx\"\n",
    "matrix = mmread(file_path)\n",
    "\n",
    "# Convert to a NetworkX graph\n",
    "# Use the appropriate function based on your NetworkX version\n",
    "try:\n",
    "    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\n",
    "except AttributeError:\n",
    "    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n",
    "\n",
    "# Compute criticality scores (assuming your function is defined)\n",
    "y_true = compute_criticality_scores(G, compute_effective_resistance)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Convert to PyG format\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "print(f\"Loaded US Power Grid graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "# Define model architecture (must match saved model)\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\"))\n",
    "model.eval()  # Set to evaluation model\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model(data).detach()\n",
    "\n",
    "# Evaluate Top-5% Nodes\n",
    "top_n = int(len(y_true) * 0.05)\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Compute Top-5% Accuracy\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ec359",
   "metadata": {
    "papermill": {
     "duration": 0.244987,
     "end_time": "2025-03-20T09:48:45.123579",
     "exception": false,
     "start_time": "2025-03-20T09:48:44.878592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6910282,
     "sourceId": 11086795,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6911061,
     "sourceId": 11087843,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1149.479621,
   "end_time": "2025-03-20T09:48:47.803504",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-20T09:29:38.323883",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
