{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc8b475c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:30.921970Z",
     "iopub.status.busy": "2025-03-19T12:17:30.921650Z",
     "iopub.status.idle": "2025-03-19T12:17:37.478077Z",
     "shell.execute_reply": "2025-03-19T12:17:37.476873Z"
    },
    "papermill": {
     "duration": 6.565302,
     "end_time": "2025-03-19T12:17:37.479761",
     "exception": false,
     "start_time": "2025-03-19T12:17:30.914459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9cc81",
   "metadata": {
    "papermill": {
     "duration": 0.005689,
     "end_time": "2025-03-19T12:17:37.492427",
     "exception": false,
     "start_time": "2025-03-19T12:17:37.486738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcc08bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:37.504936Z",
     "iopub.status.busy": "2025-03-19T12:17:37.504675Z",
     "iopub.status.idle": "2025-03-19T12:17:50.955116Z",
     "shell.execute_reply": "2025-03-19T12:17:50.954423Z"
    },
    "papermill": {
     "duration": 13.45842,
     "end_time": "2025-03-19T12:17:50.956687",
     "exception": false,
     "start_time": "2025-03-19T12:17:37.498267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05601b4",
   "metadata": {
    "papermill": {
     "duration": 0.009537,
     "end_time": "2025-03-19T12:17:50.975006",
     "exception": false,
     "start_time": "2025-03-19T12:17:50.965469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Graph Robustness Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a761e4",
   "metadata": {
    "papermill": {
     "duration": 0.010469,
     "end_time": "2025-03-19T12:17:50.994480",
     "exception": false,
     "start_time": "2025-03-19T12:17:50.984011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. Effective Graph Resistance (EGR)**  \n",
    "   $$\n",
    "   R_g = \\frac{2}{N-1} \\sum_{i=1}^{N-c} \\frac{1}{\\lambda_i}\n",
    "   $$\n",
    "   where $ \\lambda_i $ are the eigenvalues of the Laplacian matrix of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f0c3ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.018980Z",
     "iopub.status.busy": "2025-03-19T12:17:51.018149Z",
     "iopub.status.idle": "2025-03-19T12:17:51.024357Z",
     "shell.execute_reply": "2025-03-19T12:17:51.023194Z"
    },
    "papermill": {
     "duration": 0.020228,
     "end_time": "2025-03-19T12:17:51.026366",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.006138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_effective_resistance(graph):\n",
    "    laplacian = nx.laplacian_matrix(graph).toarray()\n",
    "    eigenvalues = np.linalg.eigvalsh(laplacian)\n",
    "    eigenvalues = eigenvalues[eigenvalues > 1e-8]  # Avoid zero eigenvalues\n",
    "    N = graph.number_of_nodes()\n",
    "    return (2 / (N - 1)) * np.sum(1 / eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b358c5",
   "metadata": {
    "papermill": {
     "duration": 0.013996,
     "end_time": "2025-03-19T12:17:51.050026",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.036030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2. Weighted Spectrum (WS)**  \n",
    "   $$\n",
    "   W_s = \\sum_i (1 - \\lambda_i)^n\n",
    "   $$\n",
    "   where $ n $ controls the depth of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455f0c7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.069143Z",
     "iopub.status.busy": "2025-03-19T12:17:51.068853Z",
     "iopub.status.idle": "2025-03-19T12:17:51.072421Z",
     "shell.execute_reply": "2025-03-19T12:17:51.071793Z"
    },
    "papermill": {
     "duration": 0.011974,
     "end_time": "2025-03-19T12:17:51.073683",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.061709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_weighted_spectrum(graph, n=3):\n",
    "    laplacian = nx.normalized_laplacian_matrix(graph).toarray()\n",
    "    eigenvalues = np.linalg.eigvalsh(laplacian)\n",
    "    return np.sum((1 - eigenvalues) ** n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80823061",
   "metadata": {
    "papermill": {
     "duration": 0.006018,
     "end_time": "2025-03-19T12:17:51.085956",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.079938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Algorithm 1: ILGR Embedding Module\n",
    "**Input:** Graph $ G $, input node features $ X_v $ $ \\forall v \\in V $, unknown model weights $ W $ (combination weights) and $ Q $ (aggregation weights).\n",
    "\n",
    "**Output:** Nodes embedding vector $ z_v $ $ \\forall v \\in V $.\n",
    "\n",
    "**1. Initialize**: $ h^0_v = X_v $ for all $ v \\in V $.\n",
    "**2. For each layer** $ l = 1 $ to $ L $ do:\n",
    "   - For each node $ v = 1 $ to $ V $:\n",
    "     1. Compute neighborhood embedding using attention mechanism:\n",
    "        $$\n",
    "        h^l_{N(v)} = \\text{Attention}(Q^l h^{l-1}_k) \\quad \\forall k \\in N(v)\n",
    "        $$\n",
    "     2. Compute new embedding for node $ v $ using a **skip connection**:\n",
    "        $$\n",
    "        h^l_v = \\text{ReLU} \\left( W^l \\left[ h^{l-1}_v || h^{l-2}_v || h^l_{N(v)} \\right] \\right)\n",
    "        $$\n",
    "**3. Return**: Final embedding vector $ z_v = h^L_v $ for all $ v \\in V $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ed78ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.098980Z",
     "iopub.status.busy": "2025-03-19T12:17:51.098749Z",
     "iopub.status.idle": "2025-03-19T12:17:51.103596Z",
     "shell.execute_reply": "2025-03-19T12:17:51.103013Z"
    },
    "papermill": {
     "duration": 0.012709,
     "end_time": "2025-03-19T12:17:51.104780",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.092071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ILGRNodeEmbedding(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(3, hidden_channels)  # 3 input features: degree, avg_neighbor_degree, criticality\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.attention = torch.nn.MultiheadAttention(hidden_channels, 1)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # Skip connections and attention\n",
    "        h1 = torch.relu(self.conv1(x, edge_index))\n",
    "        h2 = torch.relu(self.conv2(h1, edge_index))\n",
    "        h3 = torch.relu(self.conv3(h2, edge_index))\n",
    "        h, _ = self.attention(h3, h3, h3)\n",
    "        return torch.cat([h1, h2, h3, h], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45001f",
   "metadata": {
    "papermill": {
     "duration": 0.005835,
     "end_time": "2025-03-19T12:17:51.116898",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.111063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Regression Module\n",
    "\n",
    "The regression module applies a **non-linear transformation** using multiple layers:\n",
    "\n",
    "$$\n",
    "y_m = f(W_m \\cdot y_{m-1} + b_m)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ y_m $ is the output of the $ m^{th} $ layer.\n",
    "- $ W_m $ and $ b_m $ are the **weights** and **biases** of the $ m^{th} $ layer.\n",
    "- $ f $ is an **activation function**\n",
    "- The input to the first layer is the **node embedding**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92e7b0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.129255Z",
     "iopub.status.busy": "2025-03-19T12:17:51.128987Z",
     "iopub.status.idle": "2025-03-19T12:17:51.132785Z",
     "shell.execute_reply": "2025-03-19T12:17:51.132202Z"
    },
    "papermill": {
     "duration": 0.011073,
     "end_time": "2025-03-19T12:17:51.133857",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.122784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegressionModule(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565efd1",
   "metadata": {
    "papermill": {
     "duration": 0.005474,
     "end_time": "2025-03-19T12:17:51.145077",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.139603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ec67ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.157066Z",
     "iopub.status.busy": "2025-03-19T12:17:51.156851Z",
     "iopub.status.idle": "2025-03-19T12:17:51.160405Z",
     "shell.execute_reply": "2025-03-19T12:17:51.159826Z"
    },
    "papermill": {
     "duration": 0.010678,
     "end_time": "2025-03-19T12:17:51.161490",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.150812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ILGR(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.embedding = ILGRNodeEmbedding(hidden_channels)\n",
    "        self.regression = RegressionModule(hidden_channels * 4)  # Concatenated embeddings\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        embedding = self.embedding(x, edge_index)\n",
    "        return self.regression(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60a22f",
   "metadata": {
    "papermill": {
     "duration": 0.005422,
     "end_time": "2025-03-19T12:17:51.172767",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.167345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Criticality Score Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e93e2d",
   "metadata": {
    "papermill": {
     "duration": 0.005386,
     "end_time": "2025-03-19T12:17:51.183783",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.178397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Algorithm 3: Conventional Approach for Identifying Critical Nodes/Links\n",
    "**Input:** Graph $ G $ with $ V $ nodes.\n",
    "**Output:** Node critical scores.\n",
    "\n",
    "**1. For each node/link** $ n $ in $ V $:\n",
    "   - Remove node $ n $ from the graph $ G $.\n",
    "   - Compute robustness metric of the **residual graph** $ (G - n) $.\n",
    "   - Assign a **criticality score** to node $ n $.\n",
    "\n",
    "**2. End loop**.\n",
    "\n",
    "3. Rank nodes based on computed **criticality scores**.\n",
    "4. Top ranks correspond to the **most critical nodes**.\n",
    "**5. Return**: Top $ N\\% $ of most critical nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a82e7148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.195577Z",
     "iopub.status.busy": "2025-03-19T12:17:51.195382Z",
     "iopub.status.idle": "2025-03-19T12:17:51.198625Z",
     "shell.execute_reply": "2025-03-19T12:17:51.198074Z"
    },
    "papermill": {
     "duration": 0.010252,
     "end_time": "2025-03-19T12:17:51.199678",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.189426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_criticality_scores(graph, metric):\n",
    "    scores = []\n",
    "    for node in tqdm(graph.nodes(), desc=\"Computing Criticality Scores\"):\n",
    "        subgraph = graph.copy()\n",
    "        subgraph.remove_node(node)\n",
    "        score = metric(graph) - metric(subgraph)  # Drop in robustness\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca9767",
   "metadata": {
    "papermill": {
     "duration": 0.005398,
     "end_time": "2025-03-19T12:17:51.210760",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.205362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ranking Loss\n",
    "$$\n",
    "     L_{ij} = -f(r_{ij}) \\log(σ(\\hat{y}_{ij})) - (1 - f(r_{ij})) \\log(1 - σ(\\hat{y}_{ij}))\n",
    "     $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7d11e20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.222586Z",
     "iopub.status.busy": "2025-03-19T12:17:51.222392Z",
     "iopub.status.idle": "2025-03-19T12:17:51.227272Z",
     "shell.execute_reply": "2025-03-19T12:17:51.226492Z"
    },
    "papermill": {
     "duration": 0.012057,
     "end_time": "2025-03-19T12:17:51.228446",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.216389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def pairwise_ranking_loss(y_pred, y_true):\\n    # Compute all pairwise differences\\n    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # r_ij = r_i - r_j\\n    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # y_ij = y_i - y_j\\n\\n    # Apply sigmoid function to ground truth ranking differences f(r_ij)\\n    f_rij = torch.sigmoid(diff_true)\\n\\n    # Compute sigmoid of predicted ranking differences σ(ŷ_ij)\\n    sigma_y_pred = torch.sigmoid(diff_pred)\\n\\n    # Compute the pairwise ranking loss\\n    loss = -f_rij * torch.log(sigma_y_pred + 1e-10) - (1 - f_rij) * torch.log(1 - sigma_y_pred + 1e-10)\\n\\n    # Mask to consider only valid pairs (i < j) to avoid redundant comparisons\\n    mask = torch.triu(torch.ones_like(loss), diagonal=1).bool()\\n    loss = loss[mask]\\n\\n    # Compute mean loss over valid pairs\\n    return loss.mean()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def pairwise_ranking_loss(y_pred, y_true):\n",
    "    # Compute all pairwise differences\n",
    "    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # r_ij = r_i - r_j\n",
    "    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # y_ij = y_i - y_j\n",
    "\n",
    "    # Apply sigmoid function to ground truth ranking differences f(r_ij)\n",
    "    f_rij = torch.sigmoid(diff_true)\n",
    "\n",
    "    # Compute sigmoid of predicted ranking differences σ(ŷ_ij)\n",
    "    sigma_y_pred = torch.sigmoid(diff_pred)\n",
    "\n",
    "    # Compute the pairwise ranking loss\n",
    "    loss = -f_rij * torch.log(sigma_y_pred + 1e-10) - (1 - f_rij) * torch.log(1 - sigma_y_pred + 1e-10)\n",
    "\n",
    "    # Mask to consider only valid pairs (i < j) to avoid redundant comparisons\n",
    "    mask = torch.triu(torch.ones_like(loss), diagonal=1).bool()\n",
    "    loss = loss[mask]\n",
    "\n",
    "    # Compute mean loss over valid pairs\n",
    "    return loss.mean()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0641598",
   "metadata": {
    "papermill": {
     "duration": 0.005563,
     "end_time": "2025-03-19T12:17:51.239831",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.234268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Optimize Pairwise Loss Computation\n",
    "Replace the nested-loop pairwise loss with a vectorized implementation to handle large graphs (other version of pairwise ranking loss) :\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N(N-1)/2} \\sum_{i < j} \\log \\left( 1 + \\exp \\left( - \\text{sign}(y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)}) \\cdot (y_{\\text{pred}}^{(i)} - y_{\\text{pred}}^{(j)}) \\right) \\right)\n",
    "$$\n",
    "\n",
    "### Where:\n",
    "- $ y_{\\text{pred}}^{(i)} $ and $ y_{\\text{pred}}^{(j)} $ are the predicted values for the $i$-th and $j$-th items, respectively.\n",
    "- $ y_{\\text{true}}^{(i)} $ and $ y_{\\text{true}}^{(j)} $ are the true labels for the $i$-th and $j$-th items, respectively.\n",
    "- $ \\text{sign}(x) $ is the sign function:\n",
    "- $ \\text{sign}(x) = +1 $ if $ x > 0 $\n",
    "- $ \\text{sign}(x) = -1 $ if $ x < 0 $\n",
    "\n",
    "### Breakdown:\n",
    "\n",
    "- $ y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)} $: The difference in the true values (target ranking).\n",
    "- $ y_{\\text{pred}}^{(i)} - y_{\\text{pred}}^{(j)} $: The difference in the predicted values (model's ranking).\n",
    "- $ \\text{sign}(y_{\\text{true}}^{(i)} - y_{\\text{true}}^{(j)}) $ ensures that:\n",
    "- If the true ranking is correct (i.e., $ y_{\\text{true}}^{(i)} > y_{\\text{true}}^{(j)} $), we want $ y_{\\text{pred}}^{(i)} $ to be greater than $ y_{\\text{pred}}^{(j)} $.\n",
    "- The difference in predictions should match the expected order.\n",
    "\n",
    "This formulation helps enforce the correct ranking order between pairs, which is critical in learning-to-rank tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2408e833",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.252014Z",
     "iopub.status.busy": "2025-03-19T12:17:51.251767Z",
     "iopub.status.idle": "2025-03-19T12:17:51.255859Z",
     "shell.execute_reply": "2025-03-19T12:17:51.255131Z"
    },
    "papermill": {
     "duration": 0.011547,
     "end_time": "2025-03-19T12:17:51.257158",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.245611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairwise_ranking_loss(y_pred, y_true):\n",
    "    y_pred = y_pred.squeeze()\n",
    "    y_true = y_true.squeeze()\n",
    "    \n",
    "    # Compute all pairwise differences\n",
    "    diff_pred = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)  # Shape [N, N]\n",
    "    diff_true = y_true.unsqueeze(1) - y_true.unsqueeze(0)  # Shape [N, N]\n",
    "    \n",
    "    # Mask for valid pairs (i < j)\n",
    "    mask = torch.triu(torch.ones_like(diff_true), diagonal=1).bool()\n",
    "    diff_pred = diff_pred[mask]\n",
    "    diff_true = diff_true[mask]\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = torch.log(1 + torch.exp(-torch.sign(diff_true) * diff_pred)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296aab07",
   "metadata": {
    "papermill": {
     "duration": 0.005532,
     "end_time": "2025-03-19T12:17:51.268545",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.263013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Graph Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a7538",
   "metadata": {
    "papermill": {
     "duration": 0.005621,
     "end_time": "2025-03-19T12:17:51.279954",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.274333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Generate Synthetic Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "650d9af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.292147Z",
     "iopub.status.busy": "2025-03-19T12:17:51.291911Z",
     "iopub.status.idle": "2025-03-19T12:17:51.295506Z",
     "shell.execute_reply": "2025-03-19T12:17:51.294569Z"
    },
    "papermill": {
     "duration": 0.01098,
     "end_time": "2025-03-19T12:17:51.296691",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.285711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Power-law graph (Barabási-Albert model)\n",
    "def generate_power_law(n, m):\n",
    "    return nx.barabasi_albert_graph(n, m)\n",
    "\n",
    "# Power-law cluster graph (Holme-Kim model)\n",
    "def generate_power_law_cluster(n, m, p):\n",
    "    return nx.powerlaw_cluster_graph(n, m, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d77a2c",
   "metadata": {
    "papermill": {
     "duration": 0.005634,
     "end_time": "2025-03-19T12:17:51.308150",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.302516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### real-world datasets (load function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10975d48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.320620Z",
     "iopub.status.busy": "2025-03-19T12:17:51.320426Z",
     "iopub.status.idle": "2025-03-19T12:17:51.323214Z",
     "shell.execute_reply": "2025-03-19T12:17:51.322650Z"
    },
    "papermill": {
     "duration": 0.010139,
     "end_time": "2025-03-19T12:17:51.324359",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.314220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_real_world_graph(dataset_name):\n",
    "    G = nx.read_edgelist(dataset_name, nodetype=int)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a2551",
   "metadata": {
    "papermill": {
     "duration": 0.005614,
     "end_time": "2025-03-19T12:17:51.335942",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.330328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Convert NetworkX graph to PyTorch Geometric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76e68aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.348081Z",
     "iopub.status.busy": "2025-03-19T12:17:51.347841Z",
     "iopub.status.idle": "2025-03-19T12:17:51.352019Z",
     "shell.execute_reply": "2025-03-19T12:17:51.351451Z"
    },
    "papermill": {
     "duration": 0.011581,
     "end_time": "2025-03-19T12:17:51.353267",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.341686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nx_to_pyg(nx_graph, criticality_scores):\n",
    "    # Convert NetworkX graph to PyG format\n",
    "    pyg_data = from_networkx(nx_graph)\n",
    "\n",
    "    # Compute node features: degree, average neighbor degree, etc.\n",
    "    degrees = torch.tensor([nx_graph.degree(n) for n in nx_graph.nodes()], dtype=torch.float).view(-1, 1)\n",
    "    avg_neighbor_degrees = torch.tensor([np.mean([nx_graph.degree(neighbor) for neighbor in nx_graph.neighbors(n)]) \n",
    "                                      if nx_graph.degree(n) > 0 else 0 for n in nx_graph.nodes()], dtype=torch.float).view(-1, 1)\n",
    "    \n",
    "    # Combine features\n",
    "    pyg_data.x = torch.cat([degrees, avg_neighbor_degrees, criticality_scores.view(-1, 1)], dim=-1)\n",
    "\n",
    "    return pyg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7800a4",
   "metadata": {
    "papermill": {
     "duration": 0.005647,
     "end_time": "2025-03-19T12:17:51.364887",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.359240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Algorithm 2: ILGR Training\n",
    "**Input:** Model with unknown weights.\n",
    "**Output:** Trained model.\n",
    "\n",
    "1. Compute ground truth **criticality scores** of nodes based on graph robustness score.\n",
    "2. **For each epoch do**:\n",
    "   - Get each **node embedding** from the embedding module.\n",
    "   - Estimate **criticality scores** of nodes/links using the regression module.\n",
    "   - Update weights of both modules by solving the loss function:\n",
    "     $$\n",
    "     L_{ij} = -f(r_{ij}) \\log(σ(\\hat{y}_{ij})) - (1 - f(r_{ij})) \\log(1 - σ(\\hat{y}_{ij}))\n",
    "     $$\n",
    "3. **End loop**.\n",
    "4. Predict nodescores on the test graph.\n",
    "5. **Return**: Top $ N\\% $ of most critical nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a470314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.377136Z",
     "iopub.status.busy": "2025-03-19T12:17:51.376899Z",
     "iopub.status.idle": "2025-03-19T12:17:51.381112Z",
     "shell.execute_reply": "2025-03-19T12:17:51.380575Z"
    },
    "papermill": {
     "duration": 0.011728,
     "end_time": "2025-03-19T12:17:51.382353",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.370625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, data, y_true, epochs=100, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    data, y_true = data.to(device), y_true.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    progress_bar = tqdm(range(epochs), desc=\"Training Model\", dynamic_ncols=True)\n",
    "    \n",
    "    for epoch in progress_bar:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(data)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = pairwise_ranking_loss(y_pred, y_true)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar with loss value\n",
    "        progress_bar.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58fd9d3",
   "metadata": {
    "papermill": {
     "duration": 0.005494,
     "end_time": "2025-03-19T12:17:51.393742",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.388248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Evaluation Metrics: Top-N% Accuracy**\n",
    "\n",
    "To measure the accuracy of our framework, we use **Top-N% Accuracy**, which is defined as the percentage of overlap between the predicted Top-N% nodes/links and the ground-truth Top-N% nodes/links (computed using a conventional baseline approach). \n",
    "\n",
    "The formula for **Top-N% Accuracy** is given by:\n",
    "\n",
    "$$\n",
    "\\text{Top-N% Accuracy} = \\frac{\\left| \\{\\text{Predicted Top-N% nodes/links}\\} \\cap \\{\\text{True Top-N% nodes/links}\\} \\right|}{|V| \\times (N/100)}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ |V| $ is the total number of nodes/links in the graph.\n",
    "- $ N $ is the percentage band (e.g., Top-5%).\n",
    "- $ \\cap $ denotes the intersection between the predicted and true Top-N% sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42945ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.406200Z",
     "iopub.status.busy": "2025-03-19T12:17:51.405947Z",
     "iopub.status.idle": "2025-03-19T12:17:51.409761Z",
     "shell.execute_reply": "2025-03-19T12:17:51.409177Z"
    },
    "papermill": {
     "duration": 0.011185,
     "end_time": "2025-03-19T12:17:51.410955",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.399770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_n_accuracy(y_pred, y_true, N=5):\n",
    "    num_nodes = len(y_true)\n",
    "    top_n = int(num_nodes * (N / 100))\n",
    "\n",
    "    # Get indices of top N% nodes for predicted and true values\n",
    "    top_pred = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "    top_true = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "    # Compute accuracy as percentage of overlap\n",
    "    accuracy = len(set(top_pred.tolist()) & set(top_true.tolist())) / top_n\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850453e",
   "metadata": {
    "papermill": {
     "duration": 0.005545,
     "end_time": "2025-03-19T12:17:51.422335",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.416790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Test the framwork**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03039d5d",
   "metadata": {
    "papermill": {
     "duration": 0.005712,
     "end_time": "2025-03-19T12:17:51.433840",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.428128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1000 nodes (power-law graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5566c68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:17:51.446502Z",
     "iopub.status.busy": "2025-03-19T12:17:51.446305Z",
     "iopub.status.idle": "2025-03-19T12:21:34.224318Z",
     "shell.execute_reply": "2025-03-19T12:21:34.223469Z"
    },
    "papermill": {
     "duration": 222.785707,
     "end_time": "2025-03-19T12:21:34.225659",
     "exception": false,
     "start_time": "2025-03-19T12:17:51.439952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1000/1000 [03:34<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILGR(\n",
      "  (embedding): ILGRNodeEmbedding(\n",
      "    (conv1): SAGEConv(3, 32, aggr=mean)\n",
      "    (conv2): SAGEConv(32, 32, aggr=mean)\n",
      "    (conv3): SAGEConv(32, 32, aggr=mean)\n",
      "    (attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (regression): RegressionModule(\n",
      "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 1000/1000 [00:08<00:00, 122.89it/s, loss=0.435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Top-5% True Node Indices: [299, 409, 221, 766, 26, 244, 191, 966, 260, 27, 63, 338, 486, 212, 667, 168, 478, 535, 188, 421, 125, 552, 531, 378, 4, 82, 2, 1, 148, 52, 78, 123, 909, 544, 40, 440, 64, 235, 776, 176, 464, 604, 920, 915, 44, 86, 7, 897, 16, 239]\n",
      "Top-5% Predicted Node Indices: [27, 4, 9, 63, 260, 82, 34, 44, 6, 2, 26, 40, 47, 5, 16, 25, 21, 221, 168, 50, 7, 123, 706, 170, 74, 32, 41, 191, 54, 111, 18, 46, 534, 39, 728, 895, 435, 60, 3, 927, 188, 703, 986, 994, 56, 960, 212, 667, 672, 521]\n",
      "Top-5% Accuracy: 36.00%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate a power-law graph\n",
    "G = generate_power_law(n=1000, m=3)\n",
    "\n",
    "# Step 2: Compute criticality scores\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Step 3: Convert to PyG format with node features\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "# Step 4: Define the model\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "print(model)\n",
    "\n",
    "# Step 5: Train the model\n",
    "train_model(model, data, y_true, epochs=1000, lr=0.001)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(data).detach()  # Ensure no gradients\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model_pl.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Evaluate the top-N% nodes based on their criticality scores (true values)\n",
    "top_n = int(len(y_true) * 0.05)  # Top 5% nodes\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Display top-5% criticality scores for both true and predicted values\n",
    "# print(\"Top-5% True Criticality Scores:\", y_true[top_n_true_indices].tolist())\n",
    "# print(\"Top-5% Predicted Criticality Scores:\", y_pred[top_n_pred_indices].tolist())\n",
    "\n",
    "\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d1db6",
   "metadata": {
    "papermill": {
     "duration": 0.094379,
     "end_time": "2025-03-19T12:21:34.457252",
     "exception": false,
     "start_time": "2025-03-19T12:21:34.362873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1000 nodes (power-law cluster graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89ace8da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:21:34.646127Z",
     "iopub.status.busy": "2025-03-19T12:21:34.645771Z",
     "iopub.status.idle": "2025-03-19T12:25:05.656712Z",
     "shell.execute_reply": "2025-03-19T12:25:05.655790Z"
    },
    "papermill": {
     "duration": 211.106783,
     "end_time": "2025-03-19T12:25:05.657959",
     "exception": false,
     "start_time": "2025-03-19T12:21:34.551176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1000/1000 [03:23<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILGR(\n",
      "  (embedding): ILGRNodeEmbedding(\n",
      "    (conv1): SAGEConv(3, 32, aggr=mean)\n",
      "    (conv2): SAGEConv(32, 32, aggr=mean)\n",
      "    (conv3): SAGEConv(32, 32, aggr=mean)\n",
      "    (attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (regression): RegressionModule(\n",
      "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Model: 100%|██████████| 1000/1000 [00:06<00:00, 145.58it/s, loss=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Top-5% True Node Indices: [369, 353, 337, 464, 309, 459, 714, 823, 562, 698, 484, 810, 768, 547, 663, 544, 724, 852, 939, 906, 973, 322, 826, 635, 825, 237, 713, 512, 621, 712, 371, 213, 898, 355, 828, 734, 607, 992, 573, 968, 313, 866, 132, 280, 720, 399, 448, 137, 460, 530]\n",
      "Top-5% Predicted Node Indices: [369, 353, 714, 464, 459, 309, 810, 562, 823, 337, 768, 724, 826, 484, 547, 544, 698, 663, 973, 512, 237, 825, 906, 898, 712, 355, 322, 635, 371, 713, 621, 852, 734, 213, 866, 313, 720, 399, 573, 968, 132, 992, 186, 828, 288, 344, 326, 393, 448, 86]\n",
      "Top-5% Accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate a power-law graph cluster\n",
    "G = generate_power_law_cluster(n=1000, m=3, p=0.3)\n",
    "\n",
    "# Step 2: Compute criticality scores\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Step 3: Convert to PyG format with node features\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "# Step 4: Define the model\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "print(model)\n",
    "\n",
    "# Step 5: Train the model\n",
    "train_model(model, data, y_true, epochs=1000, lr=0.001)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "model.eval()\n",
    "y_pred = model(data).detach()  # Ensure no gradients\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model_plc.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "\n",
    "# Evaluate the top-N% nodes based on their criticality scores (true values)\n",
    "top_n = int(len(y_true) * 0.05)  # Top 5% nodes\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Display top-5% criticality scores for both true and predicted values\n",
    "# print(\"Top-5% True Criticality Scores:\", y_true[top_n_true_indices].tolist())\n",
    "# print(\"Top-5% Predicted Criticality Scores:\", y_pred[top_n_pred_indices].tolist())\n",
    "\n",
    "\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)  # Top-5% accuracy\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff0af7d",
   "metadata": {
    "papermill": {
     "duration": 0.182124,
     "end_time": "2025-03-19T12:25:06.029349",
     "exception": false,
     "start_time": "2025-03-19T12:25:05.847225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Bio Yeast Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c418fe0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:25:06.436825Z",
     "iopub.status.busy": "2025-03-19T12:25:06.436521Z",
     "iopub.status.idle": "2025-03-19T12:37:13.906831Z",
     "shell.execute_reply": "2025-03-19T12:37:13.905936Z"
    },
    "papermill": {
     "duration": 727.695934,
     "end_time": "2025-03-19T12:37:13.908357",
     "exception": false,
     "start_time": "2025-03-19T12:25:06.212423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Criticality Scores: 100%|██████████| 1458/1458 [12:07<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Bio Yeast graph with 1458 nodes and 1948 edges.\n",
      "Model loaded successfully!\n",
      "Top-5% True Node Indices: [542, 1078, 949, 640, 787, 81, 285, 714, 88, 725, 797, 829, 91, 964, 943, 1032, 645, 888, 1, 595, 155, 278, 368, 982, 996, 458, 417, 196, 268, 1027, 1085, 428, 702, 473, 908, 963, 766, 669, 567, 6, 1140, 984, 393, 869, 242, 1043, 937, 560, 406, 398, 63, 2, 850, 30, 1025, 56, 109, 1400, 484, 250, 1114, 890, 1126, 1409, 379, 31, 929, 1115, 517, 251, 201, 1440]\n",
      "Top-5% Predicted Node Indices: [245, 851, 446, 588, 1152, 762, 1030, 1021, 623, 100, 740, 1168, 1006, 896, 41, 39, 998, 1057, 530, 1096, 543, 546, 1108, 134, 796, 556, 311, 176, 116, 479, 477, 1048, 839, 194, 977, 917, 906, 991, 980, 676, 909, 294, 296, 298, 299, 33, 281, 241, 510, 375, 596, 569, 534, 850, 1322, 1315, 1316, 1325, 1324, 1317, 1318, 1319, 1323, 1320, 1321, 480, 1097, 859, 1084, 770, 824, 124]\n",
      "Top-5% Accuracy: 1.39%\n"
     ]
    }
   ],
   "source": [
    "# Load the Matrix Market file (Bio Yeast graph)\n",
    "file_path = \"/kaggle/input/bio-yeast/bio-yeast.mtx\"\n",
    "matrix = mmread(file_path)\n",
    "\n",
    "# Convert to a NetworkX graph\n",
    "# Use the appropriate function based on your NetworkX version\n",
    "try:\n",
    "    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\n",
    "except AttributeError:\n",
    "    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n",
    "\n",
    "# Compute criticality scores (assuming your function is defined)\n",
    "y_true = compute_criticality_scores(G, compute_weighted_spectrum)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Convert to PyG format\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "print(f\"Loaded Bio Yeast graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "# Define model architecture (must match saved model)\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\", weights_only=True))\n",
    "model.eval()  # Set to evaluation model\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model(data).detach()\n",
    "\n",
    "# Evaluate Top-5% Nodes\n",
    "top_n = int(len(y_true) * 0.05)\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist()) \n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Compute Top-5% Accuracy\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f58f1",
   "metadata": {
    "papermill": {
     "duration": 0.29021,
     "end_time": "2025-03-19T12:37:14.468530",
     "exception": false,
     "start_time": "2025-03-19T12:37:14.178320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### US Power Grid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e0a3de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T12:37:14.961970Z",
     "iopub.status.busy": "2025-03-19T12:37:14.961686Z",
     "iopub.status.idle": "2025-03-19T12:37:14.966664Z",
     "shell.execute_reply": "2025-03-19T12:37:14.965821Z"
    },
    "papermill": {
     "duration": 0.253982,
     "end_time": "2025-03-19T12:37:14.967908",
     "exception": false,
     "start_time": "2025-03-19T12:37:14.713926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load the Matrix Market file (US Power Grid graph)\\nfile_path = \"/kaggle/input/power-us-grid/power-US-Grid.mtx\"\\nmatrix = mmread(file_path)\\n\\n# Convert to a NetworkX graph\\n# Use the appropriate function based on your NetworkX version\\ntry:\\n    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\\nexcept AttributeError:\\n    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\\n\\n# Compute criticality scores (assuming your function is defined)\\ny_true = compute_criticality_scores(G, compute_effective_resistance)\\ny_true = torch.tensor(y_true, dtype=torch.float)\\n\\n# Convert to PyG format\\ndata = nx_to_pyg(G, y_true)\\n\\nprint(f\"Loaded US Power Grid graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\\n\\n# Define model architecture (must match saved model)\\nhidden_dim = 32\\nmodel = ILGR(hidden_dim)\\n\\n# Load trained weights\\nmodel.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\"))\\nmodel.eval()  # Set to evaluation model\\nprint(\"Model loaded successfully!\")\\n\\n# Make predictions\\ny_pred = model(data).detach()\\n\\n# Evaluate Top-5% Nodes\\ntop_n = int(len(y_true) * 0.05)\\ntop_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\\ntop_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\\n\\nprint(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\\nprint(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\\n\\n# Compute Top-5% Accuracy\\naccuracy = top_n_accuracy(y_pred, y_true, N=5)\\nprint(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Load the Matrix Market file (US Power Grid graph)\n",
    "file_path = \"/kaggle/input/power-us-grid/power-US-Grid.mtx\"\n",
    "matrix = mmread(file_path)\n",
    "\n",
    "# Convert to a NetworkX graph\n",
    "# Use the appropriate function based on your NetworkX version\n",
    "try:\n",
    "    G = nx.from_scipy_sparse_array(matrix)  # For newer versions of NetworkX\n",
    "except AttributeError:\n",
    "    G = nx.from_scipy_sparse_matrix(matrix)  # For older versions of NetworkX\n",
    "\n",
    "# Compute criticality scores (assuming your function is defined)\n",
    "y_true = compute_criticality_scores(G, compute_effective_resistance)\n",
    "y_true = torch.tensor(y_true, dtype=torch.float)\n",
    "\n",
    "# Convert to PyG format\n",
    "data = nx_to_pyg(G, y_true)\n",
    "\n",
    "print(f\"Loaded US Power Grid graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "# Define model architecture (must match saved model)\n",
    "hidden_dim = 32\n",
    "model = ILGR(hidden_dim)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/trained_model_pl.pth\"))\n",
    "model.eval()  # Set to evaluation model\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model(data).detach()\n",
    "\n",
    "# Evaluate Top-5% Nodes\n",
    "top_n = int(len(y_true) * 0.05)\n",
    "top_n_true_indices = torch.argsort(y_true.squeeze(), descending=True)[:top_n]\n",
    "top_n_pred_indices = torch.argsort(y_pred.squeeze(), descending=True)[:top_n]\n",
    "\n",
    "print(\"Top-5% True Node Indices:\", top_n_true_indices.tolist())\n",
    "print(\"Top-5% Predicted Node Indices:\", top_n_pred_indices.tolist())\n",
    "\n",
    "# Compute Top-5% Accuracy\n",
    "accuracy = top_n_accuracy(y_pred, y_true, N=5)\n",
    "print(f\"Top-5% Accuracy: {accuracy * 100:.2f}%\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074387bb",
   "metadata": {
    "papermill": {
     "duration": 0.245783,
     "end_time": "2025-03-19T12:37:15.459443",
     "exception": false,
     "start_time": "2025-03-19T12:37:15.213660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6910282,
     "sourceId": 11086795,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6911061,
     "sourceId": 11087843,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1190.963591,
   "end_time": "2025-03-19T12:37:18.411774",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-19T12:17:27.448183",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
